[
  {
    "objectID": "about/quarto_documentation_setup.html",
    "href": "about/quarto_documentation_setup.html",
    "title": "Documentation setup",
    "section": "",
    "text": "The documentation for Dareplane is generated with Quarto and quartodoc. The later is used to automatically generate API documentation for python modules. quarto uses a central _quarto.yml file to configure the documentation.\nFor the Dareplane documentation, https://github.com/bsdlab/Dareplane is the main repository, and the /docs folder therein should be considered the root for all quarto related steps.\n\n\n\n\n\n\nTo run the docs building for all modules, clone https://github.com/bsdlab/Dareplane and cd docs.\nIn the build across multiple modules, the Makefile has the following build steps defined:\n\ngenerate the main.qmd dynamically from the README.md\nextract the repositories from the first table in the main.qmd, taking the first column and expecting markdown notation for links\ndownload each repository into a /docs/modules/* directory\nbuild with quartodoc build within each /docs/modules/* folder\n\nTo create a fresh build, execute the following:\nmake clean\nmake main   # copy README -&gt; main.qmd\nmake modules.csv # extract the repos\nmake docs-gallery # build the docs within each module\nOnce the quartodoc part in each /docs/modules/* is done (make docs-gallery), we can use quartop preview (or the github publish action for Dareplane) to build the quarto website from within /docs for Dareplane. All modules will be included as we can specify a Documentation subsection with a glob in _quarto.yml:\nwebsite:  \n sidebar:\n    - id: \"main\"\n      contents:\n        - section: \"Documentation\"\n          contents:\n            - subsection:\n              auto: modules/*/index.qmd\n\n\n\nIn harmony with the general Dareplane coding philosophy, we want every module to be standalone, with very limited requirements for interoperability. This also holds for the documentation. The only requirement for the automated documentation process to be able to pick up the documentation is that there exists a _quarto.yml file in the root directory, which contains a least a section for quartodoc. E.g.:\nquartodoc:\n  package: \"dp-control-room\"\n  source_dir: \"control_room\"   # should point the the folder containing the python code\n  title: \"Documentation control room\"\nWith this setup, you can first create your documentation on a per module level, making sure it works with quartodoc build. The quartodoc build command will use doc-strings of the python functions and classes to dynamically create markdown documentation pages.\nFor debugging, it might be handy to add a general quarto website section on the per module _quarto.yml file. See the Single module quarto section for an example.\nThis can be done without interference with the generation on the across modules documentation, as the latter is only using the quartodoc part.\n\n\nThis section provides an example of how we would document a single Dareplane module.\nLet us assume we are documenting the dp-stroop module.\n\n\nStart out by creating the _quarto.yml file, containing a quartodoc section with an entry for the run_paradigm_cli function:\nquartodoc:\n  package: \"dp-stroop\"       # name of the package\n  source_dir: \"stroop_task\"  # as the source code is within this folder\n\n  title: \"Documentation for the Stroop task\"\n\n  options:\n    signature_name: full\n\n  # write sidebar where quartodoc writes its content without impacting quarto\n  sidebar:\n    file: \"_stroop_sidebar.yml\"\n\n  sections:\n    - title: \"The Stroop task\"\n      desc: |\n        :::{.callout-info}\n        The github repository for this module is located at:\n        [https://github.com/bsdlab/dp-stroop](https://github.com/bsdlab/dp-stroop)\n        :::\n\n    - subtitle: Modified Stroop task\n      package: stroop_task\n      desc: The main script to start the Stroop task from command line.\n      contents:\n        - main.run_paradigm_cli\n\n\n\nNow we can build the documentation with quartodoc build. This will create a ./reference folder with the documentation.\nAdd the ./reference folder and objects.json to the .gitignore to avoid cluttering of the repo. Docs will be generated dynamically.\necho reference/ &gt;&gt; .gitignore\necho objects.json &gt;&gt; .gitignore\necho _site/ &gt;&gt; .gitignore       # will be created from `quarto preview` see next step\n\n\n\nWith having the quartodoc section in the _quarto.yml, we already have everything we need, but it is hard validate that the documentation builds as intended. The most straight forward solution is to add a website section to the _quarto.yml, which then allow to debug with quarto preview:\nproject:\n  type: website\n\nwebsite:\n  sidebar:\n    - id: \"main\"\n      contents:\n        - section: \"Documentation\"\n          contents:\n            - reference/index.qmd\nThen run:\nquarto preview\nThis will open a browser window with the documentation.\n\n\n\nNow it is up to adding more sections to the documentation, which can be done by enriching the contents: of the quartodoc section in the _quarto.yml.\n      contents:\n        - main.run_paradigm_cli\n        - context.StroopContext\nNote:\n\nWhile the quarto part will update dynamically (hot reloading), quartodoc will need to be recompiled every time you add to the quartodoc section of the _quarto.yml.\nThe quarto preview might spawn not at the root of the created website but on a specific functions/classed documentation page. Simply prune the path in the browser to get to the root. E.g., from http://localhost:6901/reference/main.run_paradigm_cli.html to http://localhost:6901/\nquartodoc will add documentation for methods from each method’s own doc string. Avoid having a methods doc string section on the class wide doc string as this will lead to a NotImplementedError from griffe."
  },
  {
    "objectID": "about/quarto_documentation_setup.html#run-the-documentation-build-locally",
    "href": "about/quarto_documentation_setup.html#run-the-documentation-build-locally",
    "title": "Documentation setup",
    "section": "",
    "text": "To run the docs building for all modules, clone https://github.com/bsdlab/Dareplane and cd docs.\nIn the build across multiple modules, the Makefile has the following build steps defined:\n\ngenerate the main.qmd dynamically from the README.md\nextract the repositories from the first table in the main.qmd, taking the first column and expecting markdown notation for links\ndownload each repository into a /docs/modules/* directory\nbuild with quartodoc build within each /docs/modules/* folder\n\nTo create a fresh build, execute the following:\nmake clean\nmake main   # copy README -&gt; main.qmd\nmake modules.csv # extract the repos\nmake docs-gallery # build the docs within each module\nOnce the quartodoc part in each /docs/modules/* is done (make docs-gallery), we can use quartop preview (or the github publish action for Dareplane) to build the quarto website from within /docs for Dareplane. All modules will be included as we can specify a Documentation subsection with a glob in _quarto.yml:\nwebsite:  \n sidebar:\n    - id: \"main\"\n      contents:\n        - section: \"Documentation\"\n          contents:\n            - subsection:\n              auto: modules/*/index.qmd"
  },
  {
    "objectID": "about/quarto_documentation_setup.html#how-to-document-your-module",
    "href": "about/quarto_documentation_setup.html#how-to-document-your-module",
    "title": "Documentation setup",
    "section": "",
    "text": "In harmony with the general Dareplane coding philosophy, we want every module to be standalone, with very limited requirements for interoperability. This also holds for the documentation. The only requirement for the automated documentation process to be able to pick up the documentation is that there exists a _quarto.yml file in the root directory, which contains a least a section for quartodoc. E.g.:\nquartodoc:\n  package: \"dp-control-room\"\n  source_dir: \"control_room\"   # should point the the folder containing the python code\n  title: \"Documentation control room\"\nWith this setup, you can first create your documentation on a per module level, making sure it works with quartodoc build. The quartodoc build command will use doc-strings of the python functions and classes to dynamically create markdown documentation pages.\nFor debugging, it might be handy to add a general quarto website section on the per module _quarto.yml file. See the Single module quarto section for an example.\nThis can be done without interference with the generation on the across modules documentation, as the latter is only using the quartodoc part.\n\n\nThis section provides an example of how we would document a single Dareplane module.\nLet us assume we are documenting the dp-stroop module.\n\n\nStart out by creating the _quarto.yml file, containing a quartodoc section with an entry for the run_paradigm_cli function:\nquartodoc:\n  package: \"dp-stroop\"       # name of the package\n  source_dir: \"stroop_task\"  # as the source code is within this folder\n\n  title: \"Documentation for the Stroop task\"\n\n  options:\n    signature_name: full\n\n  # write sidebar where quartodoc writes its content without impacting quarto\n  sidebar:\n    file: \"_stroop_sidebar.yml\"\n\n  sections:\n    - title: \"The Stroop task\"\n      desc: |\n        :::{.callout-info}\n        The github repository for this module is located at:\n        [https://github.com/bsdlab/dp-stroop](https://github.com/bsdlab/dp-stroop)\n        :::\n\n    - subtitle: Modified Stroop task\n      package: stroop_task\n      desc: The main script to start the Stroop task from command line.\n      contents:\n        - main.run_paradigm_cli\n\n\n\nNow we can build the documentation with quartodoc build. This will create a ./reference folder with the documentation.\nAdd the ./reference folder and objects.json to the .gitignore to avoid cluttering of the repo. Docs will be generated dynamically.\necho reference/ &gt;&gt; .gitignore\necho objects.json &gt;&gt; .gitignore\necho _site/ &gt;&gt; .gitignore       # will be created from `quarto preview` see next step\n\n\n\nWith having the quartodoc section in the _quarto.yml, we already have everything we need, but it is hard validate that the documentation builds as intended. The most straight forward solution is to add a website section to the _quarto.yml, which then allow to debug with quarto preview:\nproject:\n  type: website\n\nwebsite:\n  sidebar:\n    - id: \"main\"\n      contents:\n        - section: \"Documentation\"\n          contents:\n            - reference/index.qmd\nThen run:\nquarto preview\nThis will open a browser window with the documentation.\n\n\n\nNow it is up to adding more sections to the documentation, which can be done by enriching the contents: of the quartodoc section in the _quarto.yml.\n      contents:\n        - main.run_paradigm_cli\n        - context.StroopContext\nNote:\n\nWhile the quarto part will update dynamically (hot reloading), quartodoc will need to be recompiled every time you add to the quartodoc section of the _quarto.yml.\nThe quarto preview might spawn not at the root of the created website but on a specific functions/classed documentation page. Simply prune the path in the browser to get to the root. E.g., from http://localhost:6901/reference/main.run_paradigm_cli.html to http://localhost:6901/\nquartodoc will add documentation for methods from each method’s own doc string. Avoid having a methods doc string section on the class wide doc string as this will lead to a NotImplementedError from griffe."
  },
  {
    "objectID": "libraries/dareplane_utils/time.partial_sleep.html",
    "href": "libraries/dareplane_utils/time.partial_sleep.html",
    "title": "time.partial_sleep",
    "section": "",
    "text": "time.partial_sleep\ndareplane_utils.general.time.partial_sleep(s, start, nsteps=30)\nSleep for 90% of s or up to 30ms to the end, whatever is longer",
    "crumbs": [
      "General",
      "time.partial_sleep"
    ]
  },
  {
    "objectID": "libraries/dareplane_utils/server.modify_root_logger.html",
    "href": "libraries/dareplane_utils/server.modify_root_logger.html",
    "title": "server.modify_root_logger",
    "section": "",
    "text": "server.modify_root_logger\ndareplane_utils.logging.server.modify_root_logger(logfile)",
    "crumbs": [
      "Logging",
      "server.modify_root_logger"
    ]
  },
  {
    "objectID": "libraries/dareplane_utils/logger.get_logger.html",
    "href": "libraries/dareplane_utils/logger.get_logger.html",
    "title": "logger.get_logger",
    "section": "",
    "text": "dareplane_utils.logging.logger.get_logger(\n    name,\n    add_console_handler=False,\n    colors=colors,\n    no_socket_handler=False,\n)\nGet a configured logger.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nname\nstr\nThe name of the logger.\nrequired\n\n\nadd_console_handler\nbool\nIf True, add a console handler to the logger (default is False).\nFalse\n\n\ncolors\ndict\nA dictionary of colors for log levels (default is colors).\ncolors\n\n\nno_socket_handler\nbool\nIf True, opt out of adding a socket handler for TCP streaming (default is False).\nFalse\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nlogging.Logger\nThe configured logger.",
    "crumbs": [
      "Logging",
      "logger.get_logger"
    ]
  },
  {
    "objectID": "libraries/dareplane_utils/logger.get_logger.html#parameters",
    "href": "libraries/dareplane_utils/logger.get_logger.html#parameters",
    "title": "logger.get_logger",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nname\nstr\nThe name of the logger.\nrequired\n\n\nadd_console_handler\nbool\nIf True, add a console handler to the logger (default is False).\nFalse\n\n\ncolors\ndict\nA dictionary of colors for log levels (default is colors).\ncolors\n\n\nno_socket_handler\nbool\nIf True, opt out of adding a socket handler for TCP streaming (default is False).\nFalse",
    "crumbs": [
      "Logging",
      "logger.get_logger"
    ]
  },
  {
    "objectID": "libraries/dareplane_utils/logger.get_logger.html#returns",
    "href": "libraries/dareplane_utils/logger.get_logger.html#returns",
    "title": "logger.get_logger",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\n\nlogging.Logger\nThe configured logger.",
    "crumbs": [
      "Logging",
      "logger.get_logger"
    ]
  },
  {
    "objectID": "libraries/dareplane_utils/get_channel_names.html",
    "href": "libraries/dareplane_utils/get_channel_names.html",
    "title": "get_channel_names",
    "section": "",
    "text": "get_channel_names\ndareplane_utils.stream_watcher.lsl_stream_watcher.get_channel_names(inf)",
    "crumbs": [
      "Streaming data",
      "get_channel_names"
    ]
  },
  {
    "objectID": "libraries/dareplane_utils/event_loop.EventLoop.html",
    "href": "libraries/dareplane_utils/event_loop.EventLoop.html",
    "title": "event_loop.EventLoop",
    "section": "",
    "text": "dareplane_utils.general.event_loop.EventLoop(\n    self,\n    dt_s,\n    stop_event=Event(),\n    ctx=None,\n)\n\n\n\n\n\nName\nDescription\n\n\n\n\nvalidate_callback\nCheck that every callback accepts at least a kwarg with ‘ctx’\n\n\n\n\n\ndareplane_utils.general.event_loop.EventLoop.validate_callback(cb)\nCheck that every callback accepts at least a kwarg with ‘ctx’",
    "crumbs": [
      "General",
      "event_loop.EventLoop"
    ]
  },
  {
    "objectID": "libraries/dareplane_utils/event_loop.EventLoop.html#methods",
    "href": "libraries/dareplane_utils/event_loop.EventLoop.html#methods",
    "title": "event_loop.EventLoop",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nvalidate_callback\nCheck that every callback accepts at least a kwarg with ‘ctx’\n\n\n\n\n\ndareplane_utils.general.event_loop.EventLoop.validate_callback(cb)\nCheck that every callback accepts at least a kwarg with ‘ctx’",
    "crumbs": [
      "General",
      "event_loop.EventLoop"
    ]
  },
  {
    "objectID": "libraries/dareplane_utils/time.full_speed.html",
    "href": "libraries/dareplane_utils/time.full_speed.html",
    "title": "time.full_speed",
    "section": "",
    "text": "time.full_speed\ndareplane_utils.general.time.full_speed(s, start)",
    "crumbs": [
      "General",
      "time.full_speed"
    ]
  },
  {
    "objectID": "libraries/dareplane_utils/time.sleep_s.html",
    "href": "libraries/dareplane_utils/time.sleep_s.html",
    "title": "time.sleep_s",
    "section": "",
    "text": "dareplane_utils.general.time.sleep_s(\n    s,\n    partial_sleep_threshold=0.0005,\n    nsteps=30,\n)\nSleep for a specified duration with partial sleep optimization.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ns\nfloat\nThe total duration to sleep in seconds.\nrequired\n\n\npartial_sleep_threshold\nfloat\nThe threshold duration above which partial sleep optimization is applied, by default 0.0005. I.e., only for durations s above the threshold, the optimization is applied.\n0.0005\n\n\nnsteps\nint\nThe number of steps for partial sleep, by default 30. Empirical testing showed very good accuracy for 30. If you want to optimize for CPU load, reduce to nsteps &gt; 4.\n30",
    "crumbs": [
      "General",
      "time.sleep_s"
    ]
  },
  {
    "objectID": "libraries/dareplane_utils/time.sleep_s.html#parameters",
    "href": "libraries/dareplane_utils/time.sleep_s.html#parameters",
    "title": "time.sleep_s",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\ns\nfloat\nThe total duration to sleep in seconds.\nrequired\n\n\npartial_sleep_threshold\nfloat\nThe threshold duration above which partial sleep optimization is applied, by default 0.0005. I.e., only for durations s above the threshold, the optimization is applied.\n0.0005\n\n\nnsteps\nint\nThe number of steps for partial sleep, by default 30. Empirical testing showed very good accuracy for 30. If you want to optimize for CPU load, reduce to nsteps &gt; 4.\n30",
    "crumbs": [
      "General",
      "time.sleep_s"
    ]
  },
  {
    "objectID": "main.html",
    "href": "main.html",
    "title": "Dareplane",
    "section": "",
    "text": "Dareplane is a modular and broad technology agnostic open source software platform for brain-computer interface research. LSL is used for data communication and TCP sockets for module communication. The platform is designed to be minimalistic and to allow for easy development of custom modules, with minimal overhead of integrating existing code.\nThe platform and first performance evaluations are published in Dold et al., 2025, J. Neural Eng. 22 026029\nThe target users are developers of experimental setups who require customized software components, or who just want to have full control over the functionality of data I/O, algorithmic processing, and/or on stimulation and feedback. For this user group, Dareplane aims to provide a minimalistic framework which allows to develop and integrate bespoke modules in a simple way. It is a mind-child of the https://suckless.org/ philosophy and tries to adapt it in a pragmatic manner with research in the focus.\nIf you are looking for a setup that is more or less ready to use out of the box, you will be better of using a more mature framework which is oriented towards more plug-and-play components. In any case it is good to have a look at the other frameworks section.",
    "crumbs": [
      "Home",
      "Introduction"
    ]
  },
  {
    "objectID": "main.html#the-design-philosophy-of-dareplane",
    "href": "main.html#the-design-philosophy-of-dareplane",
    "title": "Dareplane",
    "section": "The design philosophy of Dareplane",
    "text": "The design philosophy of Dareplane\nThe basic idea of the Dareplane platform is to provide a modular approach for software components used for research of neuro-technology. The design goals are:\n\nto provide reusable single purpose modules which can be integrated into a larger system;\nto be technology agnostic, so that modules can be used with different hardware and developed in different languages;\nto be minimalistic in terms of constraints and required overhead for integrating existing software into the platform.\n\nThe implications of these design goals are:\n\nA common channel of communication between modules is required, which should work with a wide range of hardware and software. For Dareplane this is solved by using TCP sockets for module communication. For data transfer, the awesome LSL framework is used.\nA common protocol for communication is required, which Dareplane implements as string communication using what is referred to as primary commands. This is an arbitray string following by a pipe delimiter and potentially a json payload. Imagine a module for recording EEG data from a single data source. On a high level, a command you would want to use is: STARTRECORDING|{\"path\":\"./mydatafolder/\", \"file\": \"myrecoding.xdf\"}.",
    "crumbs": [
      "Home",
      "Introduction"
    ]
  },
  {
    "objectID": "main.html#overview-of-the-dareplane-projects-and-individual-modules",
    "href": "main.html#overview-of-the-dareplane-projects-and-individual-modules",
    "title": "Dareplane",
    "section": "Overview of the Dareplane projects and individual modules",
    "text": "Overview of the Dareplane projects and individual modules\n\n\n\nLink\nDescription\n\n\n\n\ndp-strawmam-module\na strawman repository as starting point for developing your modules\n\n\ndp-control-room\nthe central module which combines individual modules to a system\n\n\ndp-lsl-recording\nmodule for interacting with the LSL LabRecorder\n\n\ndp-mockup-streamer\nmodule for creating mock-up streams from files or generating random data\n\n\ndp-copydraw\nmodule to run the CopyDraw - Castano et al. 2019 paradigm\n\n\ndp-multiband-regression\nmodule to perform a multiband regression based on a multichannel data stream\n\n\ndp-bollinger-control\na Bollinger Band control module\n\n\ndp-ao-communicatio\na C++ module interacting with the Alpha Omega’s API\n\n\ndp-arduino-stimulator\nmodule to use an Arduino as a mock-up of a neuro-stimulator\n\n\ndp-picoscope-streamer\nmodule to stream data from a Picoscope to LSL\n\n\ndp-passthrough\na simple passthrough Dareplane module for performance testing\n\n\ndp-threshold-controller\na threshold control module with grace periods\n\n\ndp-cortec-bic\nmodule to interact with the API of the CorTec BrainInterchange\n\n\ndp-cvep-speller\na c-VEP speller paradigm module\n\n\ndp-stroop\nA classical and modified version of the Stroop color word task.\n\n\ndp-c-sdl2-example\nPrototype of creating a paradigm application with SDL in pure C.\n\n\n\n\n\n\nFor python modules / development\nIf you are building your modules in python, or using the existing python modules, the dareplane-utils python module will provide some core functionality which most modules will need.\npip install dareplane-utils\nThe module provides basic functionality around TCP servers, logging, and collecting data from LSL streams.\n\nControl Room module\nThe control room module is the central piece for composition of modules to a full setup. Modules you need in your experiment are added within a setup configuration file (see ./examples and the documentation in the control room)",
    "crumbs": [
      "Home",
      "Introduction"
    ]
  },
  {
    "objectID": "main.html#getting-started",
    "href": "main.html#getting-started",
    "title": "Dareplane",
    "section": "Getting started",
    "text": "Getting started\nA good starting point is the c-VEP experiment, which contains a setup script that downloads and configures a cVEP speller, outlining how modules need to be configured for interaction.",
    "crumbs": [
      "Home",
      "Introduction"
    ]
  },
  {
    "objectID": "main.html#citation",
    "href": "main.html#citation",
    "title": "Dareplane",
    "section": "Citation",
    "text": "Citation\nIf you use Dareplane in your work, please cite the following paper:\n@article{Dold_2025,\n  doi = {10.1088/1741-2552/adbb20},\n  url = {https://dx.doi.org/10.1088/1741-2552/adbb20},\n  year = {2025},\n  month = {mar},\n  publisher = {IOP Publishing},\n  volume = {22},\n  number = {2},\n  pages = {026029},\n  author = {Dold, Matthias and Pereira, Joana and Sajonz, Bastian and Coenen, Volker A and Thielen, Jordy and Janssen, Marcus L F and Tangermann, Michael},\n  title = {Dareplane: a modular open-source software platform for BCI research with application in closed-loop deep brain stimulation},\n  journal = {Journal of Neural Engineering},\n}",
    "crumbs": [
      "Home",
      "Introduction"
    ]
  },
  {
    "objectID": "main.html#other-frameworks",
    "href": "main.html#other-frameworks",
    "title": "Dareplane",
    "section": "Other frameworks",
    "text": "Other frameworks\nThis is a non-exhaustive list of other frameworks which might be more suitable depending on your needs:\n\nBCI2000\nMedusabci\ntimeflux",
    "crumbs": [
      "Home",
      "Introduction"
    ]
  },
  {
    "objectID": "modules/index.html",
    "href": "modules/index.html",
    "title": "Dareplane",
    "section": "",
    "text": "Utility librarires\nCollection of libraries providing functionality to Dareplane\n\n\n  \n    \n        \n            dareplane-utils\n        \n    \n    \n    \n        \n    \n    \n    \n    \n      \n       \n        Python module with various utility functions for Dareplane modules\n      \n      \n        \n          View documentation\n        \n\n         \n\n      \n    \n    \n  \n\n\n\nSingle module documentation\nDareplane is structured in individual module, each providing its own documentation\n\n\n  \n    \n        \n            dp-strawman-module\n        \n    \n    \n    \n        \n    \n    \n    \n    \n      \n      \n      \n        \n          View documentation\n        \n\n         \n\n      \n    \n    \n  \n\n  \n    \n        \n            dp-control-room\n        \n    \n    \n    \n        \n    \n    \n    \n    \n      \n      \n      \n        \n          View documentation\n        \n\n         \n\n      \n    \n    \n  \n\n  \n    \n        \n            dp-lsl-recording\n        \n    \n    \n    \n        \n    \n    \n    \n    \n      \n      \n      \n        \n          View documentation\n        \n\n         \n\n      \n    \n    \n  \n\n  \n    \n        \n            dp-mockup-streamer\n        \n    \n    \n    \n        \n    \n    \n    \n    \n      \n      \n      \n        \n          View documentation\n        \n\n         \n\n      \n    \n    \n  \n\n  \n    \n        \n            dp-copydraw\n        \n    \n    \n    \n        \n    \n    \n    \n    \n      \n      \n      \n        \n          View documentation\n        \n\n         \n\n      \n    \n    \n  \n\n  \n    \n        \n            dp-multiband-regression\n        \n    \n    \n    \n        \n    \n    \n    \n    \n      \n      \n      \n        \n          View documentation\n        \n\n         \n\n      \n    \n    \n  \n\n  \n    \n        \n            dp-bollinger-control\n        \n    \n    \n    \n        \n    \n    \n    \n    \n      \n      \n      \n        \n          View documentation\n        \n\n         \n\n      \n    \n    \n  \n\n  \n    \n        \n            dp-ao-communication\n        \n    \n    \n    \n        \n    \n    \n    \n    \n      \n      \n      \n        \n          View documentation\n        \n\n         \n\n      \n    \n    \n  \n\n  \n    \n        \n            dp-arduino-stimulator\n        \n    \n    \n    \n        \n    \n    \n    \n    \n      \n      \n      \n        \n          View documentation\n        \n\n         \n\n      \n    \n    \n  \n\n  \n    \n        \n            dp-picoscope-streamer\n        \n    \n    \n    \n        \n    \n    \n    \n    \n      \n      \n      \n        \n          View documentation\n        \n\n         \n\n      \n    \n    \n  \n\n  \n    \n        \n            dp-passthrough\n        \n    \n    \n    \n        \n    \n    \n    \n    \n      \n      \n      \n        \n          View documentation\n        \n\n         \n\n      \n    \n    \n  \n\n  \n    \n        \n            dp-threshold-controller\n        \n    \n    \n    \n        \n    \n    \n    \n    \n      \n      \n      \n        \n          View documentation\n        \n\n         \n\n      \n    \n    \n  \n\n  \n    \n        \n            dp-cortec-bic\n        \n    \n    \n    \n        \n    \n    \n    \n    \n      \n      \n      \n        \n          View documentation\n        \n\n         \n\n      \n    \n    \n  \n\n  \n    \n        \n            dp-cvep-speller\n        \n    \n    \n    \n        \n    \n    \n    \n    \n      \n      \n      \n        \n          View documentation\n        \n\n         \n\n      \n    \n    \n  \n\n  \n    \n        \n            dp-stroop\n        \n    \n    \n    \n        \n    \n    \n    \n    \n      \n      \n      \n        \n          View documentation\n        \n\n         \n\n      \n    \n    \n  \n\n  \n    \n        \n            dp-c-sdl2-example\n        \n    \n    \n    \n        \n    \n    \n    \n    \n      \n      \n      \n        \n          View documentation\n        \n\n         \n\n      \n    \n    \n  \n\n\n\nNo matching items"
  },
  {
    "objectID": "modules/dp-stroop/reference/utils.marker.MarkerWriter.html",
    "href": "modules/dp-stroop/reference/utils.marker.MarkerWriter.html",
    "title": "utils.marker.MarkerWriter",
    "section": "",
    "text": "stroop_task.utils.marker.MarkerWriter(\n    self,\n    write_to_serial=True,\n    write_to_lsl=True,\n    write_to_logger=False,\n    serial_port='COM4',\n    utf8_encoded=True,\n)\nClass for interacting with the virtual serial port provided by the BV TriggerBox and an LSL marker stream\n\n\n\n\n\nName\nDescription\n\n\n\n\nwrite\nFor this paradigm the writer will have the potential for separate markers for LSL and the parallel port\n\n\n\n\n\nstroop_task.utils.marker.MarkerWriter.write(data, lsl_marker=None)\nFor this paradigm the writer will have the potential for separate markers for LSL and the parallel port\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndata\n\ndata to be written to the serial port\nrequired\n\n\nlsl_marker\nstr | None\nif None, the data is written to the serial port and the LSL stream otherwise the lsl_marker is written to the LSL stream\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\nbyteswritten\nint\nnumber of bytes written to the serial port if self.serial_writer is defined"
  },
  {
    "objectID": "modules/dp-stroop/reference/utils.marker.MarkerWriter.html#methods",
    "href": "modules/dp-stroop/reference/utils.marker.MarkerWriter.html#methods",
    "title": "utils.marker.MarkerWriter",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nwrite\nFor this paradigm the writer will have the potential for separate markers for LSL and the parallel port\n\n\n\n\n\nstroop_task.utils.marker.MarkerWriter.write(data, lsl_marker=None)\nFor this paradigm the writer will have the potential for separate markers for LSL and the parallel port\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndata\n\ndata to be written to the serial port\nrequired\n\n\nlsl_marker\nstr | None\nif None, the data is written to the serial port and the LSL stream otherwise the lsl_marker is written to the LSL stream\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\nbyteswritten\nint\nnumber of bytes written to the serial port if self.serial_writer is defined"
  },
  {
    "objectID": "modules/dp-stroop/reference/index.html",
    "href": "modules/dp-stroop/reference/index.html",
    "title": "Documentation for the Stroop task",
    "section": "",
    "text": "The github repository for this module is located at: https://github.com/bsdlab/dp-stroop\n\n\n\nThe main script to start the Stroop task from command line.\n\n\n\nmain.run_paradigm_cli\nStarting the Stroop paradigm standalone in a pyglet window\n\n\nmain.run_paradigm\nRun the two-word Stroop task paradigm.\n\n\nmain.run_paradigm_classical\nThe arrangement and colors where drawn randomly once, but are then fixed\n\n\ncontext.StroopContext\nA class to represent the context for the Stroop task.\n\n\ntask_manager.StroopTaskStateManager\nA state manager for the Stroop task providing callbacks for state transitions from:\n\n\nutils.marker.utf8_write\nConverts integer data into a UTF-8 byte string\n\n\nutils.marker.port_writer\nWrites data to a serial port with a specified pulse width.\n\n\nutils.marker.MarkerWriter\nClass for interacting with the virtual serial",
    "crumbs": [
      "Home",
      "Documentation",
      "Dp Stroop",
      "Documentation for the Stroop task"
    ]
  },
  {
    "objectID": "modules/dp-stroop/reference/index.html#the-stroop-task",
    "href": "modules/dp-stroop/reference/index.html#the-stroop-task",
    "title": "Documentation for the Stroop task",
    "section": "",
    "text": "The github repository for this module is located at: https://github.com/bsdlab/dp-stroop\n\n\n\nThe main script to start the Stroop task from command line.\n\n\n\nmain.run_paradigm_cli\nStarting the Stroop paradigm standalone in a pyglet window\n\n\nmain.run_paradigm\nRun the two-word Stroop task paradigm.\n\n\nmain.run_paradigm_classical\nThe arrangement and colors where drawn randomly once, but are then fixed\n\n\ncontext.StroopContext\nA class to represent the context for the Stroop task.\n\n\ntask_manager.StroopTaskStateManager\nA state manager for the Stroop task providing callbacks for state transitions from:\n\n\nutils.marker.utf8_write\nConverts integer data into a UTF-8 byte string\n\n\nutils.marker.port_writer\nWrites data to a serial port with a specified pulse width.\n\n\nutils.marker.MarkerWriter\nClass for interacting with the virtual serial",
    "crumbs": [
      "Home",
      "Documentation",
      "Dp Stroop",
      "Documentation for the Stroop task"
    ]
  },
  {
    "objectID": "modules/dp-stroop/reference/main.run_paradigm.html",
    "href": "modules/dp-stroop/reference/main.run_paradigm.html",
    "title": "main.run_paradigm",
    "section": "",
    "text": "stroop_task.main.run_paradigm(\n    n_trials=60,\n    language='english',\n    logger_level=None,\n    focus='color',\n    write_to_serial=True,\n    random_wait=False,\n    show_fps=False,\n)\nRun the two-word Stroop task paradigm.\nThis function sets up and runs the two-word Stroop task paradigm using the Pyglet library. It initializes the logging configuration, creates the context for the Stroop task, sets up the window, and manages the task state. The function also adds the drawing callbacks and starts the task after a short delay.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nn_trials\nint\nThe number of trials to run in a block - needs to be an integer divisible by 6 for balancing. Default is 60.\n60\n\n\nlanguage\nstr\nThe language setting for the Stroop task. Default is “english”.\n'english'\n\n\nlogger_level\nstr | None\nThe logging level to set for the logger. If None, the level from the configuration file is used. Default is None.\nNone\n\n\nfocus\nstr\nThe focus of the task, either “text” or “color”. Default is “color”.\n'color'\n\n\nwrite_to_serial\nbool\nWhether to write markers to a serial port. Default is True.\nTrue\n\n\nrandom_wait\nbool\nWhether to use a random wait between trials. Default is False. If false, the user is required to push the arrow-down button for at least 500ms to start the next trial. If true, a random inter-trial-interval will be used. See configs/task.yaml and the wait_time_min_s and wait_time_max_s values therein.\nFalse\n\n\nshow_fps\nbool\nWhether to show the frames per second (FPS) on the screen. Default is False.\nFalse\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nNone"
  },
  {
    "objectID": "modules/dp-stroop/reference/main.run_paradigm.html#parameters",
    "href": "modules/dp-stroop/reference/main.run_paradigm.html#parameters",
    "title": "main.run_paradigm",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nn_trials\nint\nThe number of trials to run in a block - needs to be an integer divisible by 6 for balancing. Default is 60.\n60\n\n\nlanguage\nstr\nThe language setting for the Stroop task. Default is “english”.\n'english'\n\n\nlogger_level\nstr | None\nThe logging level to set for the logger. If None, the level from the configuration file is used. Default is None.\nNone\n\n\nfocus\nstr\nThe focus of the task, either “text” or “color”. Default is “color”.\n'color'\n\n\nwrite_to_serial\nbool\nWhether to write markers to a serial port. Default is True.\nTrue\n\n\nrandom_wait\nbool\nWhether to use a random wait between trials. Default is False. If false, the user is required to push the arrow-down button for at least 500ms to start the next trial. If true, a random inter-trial-interval will be used. See configs/task.yaml and the wait_time_min_s and wait_time_max_s values therein.\nFalse\n\n\nshow_fps\nbool\nWhether to show the frames per second (FPS) on the screen. Default is False.\nFalse"
  },
  {
    "objectID": "modules/dp-stroop/reference/main.run_paradigm.html#returns",
    "href": "modules/dp-stroop/reference/main.run_paradigm.html#returns",
    "title": "main.run_paradigm",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\n\nNone"
  },
  {
    "objectID": "modules/dp-stroop/reference/utils.marker.port_writer.html",
    "href": "modules/dp-stroop/reference/utils.marker.port_writer.html",
    "title": "utils.marker.port_writer",
    "section": "",
    "text": "stroop_task.utils.marker.port_writer(port, data, pulsewidth=0.01)\nWrites data to a serial port with a specified pulse width.\nThis function is typically used for writing to the BrainVision trigger box. It writes the actual data to the port, waits for the specified pulse width, and then writes a zero byte to the port.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nport\nserial.Serial\nThe serial port object to which the data will be written.\nrequired\n\n\ndata\nlist[int] | int\nThe data to be written to the serial port. Can be a single integer or a list of integers.\nrequired\n\n\npulsewidth\nfloat\nThe duration in seconds to wait between writing the actual data and the zero byte. Default is 0.01 seconds.\n0.01\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nint\nThe number of bytes written to the serial port."
  },
  {
    "objectID": "modules/dp-stroop/reference/utils.marker.port_writer.html#parameters",
    "href": "modules/dp-stroop/reference/utils.marker.port_writer.html#parameters",
    "title": "utils.marker.port_writer",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nport\nserial.Serial\nThe serial port object to which the data will be written.\nrequired\n\n\ndata\nlist[int] | int\nThe data to be written to the serial port. Can be a single integer or a list of integers.\nrequired\n\n\npulsewidth\nfloat\nThe duration in seconds to wait between writing the actual data and the zero byte. Default is 0.01 seconds.\n0.01"
  },
  {
    "objectID": "modules/dp-stroop/reference/utils.marker.port_writer.html#returns",
    "href": "modules/dp-stroop/reference/utils.marker.port_writer.html#returns",
    "title": "utils.marker.port_writer",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\n\nint\nThe number of bytes written to the serial port."
  },
  {
    "objectID": "modules/dp-control-room/reference/callbacks.html",
    "href": "modules/dp-control-room/reference/callbacks.html",
    "title": "callbacks",
    "section": "",
    "text": "callbacks\ncallbacks"
  },
  {
    "objectID": "modules/dp-control-room/reference/main.html",
    "href": "modules/dp-control-room/reference/main.html",
    "title": "main",
    "section": "",
    "text": "main\nmain"
  },
  {
    "objectID": "modules/dp-control-room/reference/gui.layout.html",
    "href": "modules/dp-control-room/reference/gui.layout.html",
    "title": "gui.layout",
    "section": "",
    "text": "gui.layout\ngui.layout"
  },
  {
    "objectID": "modules/dp-control-room/reference/index.html",
    "href": "modules/dp-control-room/reference/index.html",
    "title": "Documentation control room",
    "section": "",
    "text": "The control room is one way of composing Dareplane modules to experimental setups. \n\nThe github repository for this module is located at: https://github.com/bsdlab/dp-control-room/tree/main\n\n\n\nThe main script to start and spawn the control_room.\n\n\n\nmain\n\n\n\n\n\n\n\nUI components implemented in dash are the core of the control room.\n\n\n\ngui.app\n\n\n\ngui.callbacks\n\n\n\ngui.layout\n\n\n\n\n\n\n\nThe control_room spawns and manages the life-times of other python modules.\n\n\n\nprocesses\n\n\n\nconnection\n\n\n\nsocket\n\n\n\n\n\n\n\nThe control_room also routes control_room callbacks, which allow intermodule communication if this is not solved by using something like LSL.\n\n\n\ncallbacks\n\n\n\n\n\n\n\nUtils of the control_room concern mainly logging. This relates to providing a TCP that listenes on the standard port for python logging (9020), and therefore consolidates all logging messages shared this way. E.g., when using dareplane-utils and the from dareplane_utils.logging.logger import get_logger.\n\n\n\nutils.logging\n\n\n\nutils.logserver",
    "crumbs": [
      "Home",
      "Documentation",
      "Dp Control Room",
      "Documentation control room"
    ]
  },
  {
    "objectID": "modules/dp-control-room/reference/index.html#control-room-functionality",
    "href": "modules/dp-control-room/reference/index.html#control-room-functionality",
    "title": "Documentation control room",
    "section": "",
    "text": "The control room is one way of composing Dareplane modules to experimental setups. \n\nThe github repository for this module is located at: https://github.com/bsdlab/dp-control-room/tree/main\n\n\n\nThe main script to start and spawn the control_room.\n\n\n\nmain\n\n\n\n\n\n\n\nUI components implemented in dash are the core of the control room.\n\n\n\ngui.app\n\n\n\ngui.callbacks\n\n\n\ngui.layout\n\n\n\n\n\n\n\nThe control_room spawns and manages the life-times of other python modules.\n\n\n\nprocesses\n\n\n\nconnection\n\n\n\nsocket\n\n\n\n\n\n\n\nThe control_room also routes control_room callbacks, which allow intermodule communication if this is not solved by using something like LSL.\n\n\n\ncallbacks\n\n\n\n\n\n\n\nUtils of the control_room concern mainly logging. This relates to providing a TCP that listenes on the standard port for python logging (9020), and therefore consolidates all logging messages shared this way. E.g., when using dareplane-utils and the from dareplane_utils.logging.logger import get_logger.\n\n\n\nutils.logging\n\n\n\nutils.logserver",
    "crumbs": [
      "Home",
      "Documentation",
      "Dp Control Room",
      "Documentation control room"
    ]
  },
  {
    "objectID": "modules/dp-control-room/reference/utils.logging.html",
    "href": "modules/dp-control-room/reference/utils.logging.html",
    "title": "utils.logging",
    "section": "",
    "text": "utils.logging\nutils.logging"
  },
  {
    "objectID": "modules/dp-control-room/reference/gui.app.html",
    "href": "modules/dp-control-room/reference/gui.app.html",
    "title": "gui.app",
    "section": "",
    "text": "gui.app\ngui.app"
  },
  {
    "objectID": "examples/index.html",
    "href": "examples/index.html",
    "title": "Dareplane",
    "section": "",
    "text": "Creating modules\n\n\n\n  \n    \n        \n            Hello world from Dareplane\n        \n    \n    \n    \n        \n    \n    \n    \n    \n      \n       \n        Building your first module based of the strawmen module.\n\n      \n      \n        \n          View example\n        \n\n         \n\n      \n    \n    \n  \n\n\n\nSetup scripts\n\n\n\n  \n    \n        \n            c-VEP experiment\n        \n    \n    \n    \n        \n    \n    \n    \n    \n      \n       \n        Walk through the [setup script for c-VEP BCI](https://github.com/thijor/dp-cvep).\n\n      \n      \n        \n          View example\n        \n\n         \n\n      \n    \n    \n  \n\n\n\nNo matching items",
    "crumbs": [
      "Home",
      "Examples"
    ]
  },
  {
    "objectID": "examples/hello_world.html",
    "href": "examples/hello_world.html",
    "title": "Hello World for Dareplane with python modules",
    "section": "",
    "text": "This example will guide you through the process of creating a simple motor imagery task as a Dareplane module and then hook it up with a mock-up data streamer as well as LSL recording. Completing this example you will have a data source (mockup only), a paradigm providing visual queues and markers and finally recording of markers and streaming data with LSL into an *.xdf file.\n\n\nInstall the dareplane-utils to make use of the default TCP server. E.g. via pip install dareplane-utils.\n\n\n\nFirst, lets decide to call the module dp-mi-paradigm. The prefix of dp- for Dareplane is arbitrary and you can of course choose not to use it.\n\n\nTo start, get the dp-strawman-module and read the README.md therein carefully. After that you should know how to build upon the strawman. So lets rename the relevant folders. The content of our new module folder ./dp-mi-paradigm should then look like this:\n├── LICENSE\n├── README.md\n├── api\n│   └── server.py\n├── configs\n├── mi_paradigm\n│   ├── main.py\n│   └── utils\n│       └── logging.py\n└── tests\n\n\n\nFor our paradigm we decide to show simple instructions for motor imagination of left (L) and right ( R) hand movement by displaying letters ‘L’ and ‘R’ as well as a fixation cross ‘+’ using psychopy. In addition, we want to send markers to an LSL stream capturing when a direction is shown.\nSo our ./mi_paradigm/main.py could look like this.\n\nfrom fire import Fire\nimport time\nimport random\nimport pylsl\nfrom psychopy.visual import TextStim, Window\n\nfrom mi_paradigm.utils.logging import logger\n\nlogger.setLevel(10)\n\nBG_COLOR = (0, 0, 0)\nTEXT_COLOR = (1, 0, 0)\n\n# timing parameters\nt_pre = 1\nt_show = 1\nt_post = 1\n\n\n# LSL outlet - for convenience we also display to the logger\nclass Outlet:\n    def __init__(self):\n        self.logger = logger\n        info = pylsl.StreamInfo(name=\"markers\", channel_format=\"string\")\n        self.outlet = pylsl.StreamOutlet(info)\n\n    def push_sample(self, sample: str):\n        self.logger.debug(f\"Pushing sample {sample}\")\n        self.outlet.push_sample([sample])\n\n# Sometimes is is more convenient to have a paradigm instance which can be\n# kept alive globally. This especially holds if the server we will wrap around\n# this module will not call psychopy in a subprocess\n# --&gt; So for the example, add a class\nclass Paradigm:\n    def __init__(self):\n        self.open_window()\n\n    def open_window(self):\n        self.win = Window((800, 600), screen=1, color=BG_COLOR)\n        self.rstim = TextStim(win=self.win, text=\"R\", color=TEXT_COLOR)\n        self.lstim = TextStim(win=self.win, text=\"L\", color=TEXT_COLOR)\n        self.fix_cross = TextStim(win=self.win, text=\"+\", color=TEXT_COLOR)\n\n    def close_window(self):\n        self.win.close()\n\n\ndef run_mi_task(paradigm: Paradigm, nrepetitions: int = 4) -&gt; int:\n    outlet = Outlet()\n    win = paradigm.win\n    fix_cross = paradigm.fix_cross\n    rstim = paradigm.rstim\n    lstim = paradigm.lstim\n\n    fix_cross.draw()\n    win.flip()\n\n    # create a balanced set\n    directions = [\"R\"] * (nrepetitions // 2) + [\"L\"] * (nrepetitions // 2)\n    random.shuffle(directions)\n\n    for i, dir in enumerate(directions):\n        fix_cross.draw()\n        win.flip()\n        outlet.push_sample(\"new_trial\")\n\n        time.sleep(t_pre)\n\n        if dir == \"R\":\n            rstim.draw()\n        else:\n            lstim.draw()\n\n        win.flip()\n        outlet.push_sample(dir)\n\n        # clear screen and sleep for post\n        time.sleep(t_show)\n        win.flip()\n        outlet.push_sample(\"cleared\")\n\n        win.flip()\n        time.sleep(t_post)\n\n    return 0\n\n\nif __name__ == \"__main__\":\n\n    from functools import partial\n    pdm = Paradigm()\n    Fire(partial(run_mi_task, pdm))\nThis should be all we need for being able to test the paradigm via python -m mi_paradigm.main. Test it like this and make sure it works (especially installing requirements!).\n\n\n\nNext we need to add the server which will allow communication within a Dareplane setup. This requires just a few lines and since we started from the strawman, it actually just requires us to properly import the run_mi_task and Paradigm, intializing a Paradigm instance and adding it to the primary commands dictionary in ./api/server.py, partially defining the correct Paradigm instance.\nfrom fire import Fire\n\nfrom functools import partial\nfrom mi_paradigm.main import run_mi_task, Paradigm\nfrom mi_paradigm.utils.logging import logger\n\nfrom dareplane_utils.default_server.server import DefaultServer\n\n\ndef main(port: int = 8080, ip: str = \"127.0.0.1\", loglevel: int = 30):\n    pdm = Paradigm()\n\n    logger.setLevel(loglevel)\n    logger.debug(\"Paradigm created\")\n\n    # partial is used so taht the function call will use the pdm instance\n    pcommand_map = {\"RUN\": partial(run_mi_task, pdm)}\n\n   # ... rest is left unchanged\nNow you are ready for the next level of testing, which is to make sure, we can run the task via the server. Just spawn up the server with python -m api.server and connect via e.g. telnet 127.0.0.1 8080. Then send the RUN command in telnet and verify that the paradigm is played correctly.\nOnce this is successful, you have completed your first Dareplane module. Congratulations !\n\n\n\n\nIt is now time to integrate the dp-mi-paradigm with other modules. This is done using the dp-control-room. If you do not yet have it, clone it from git and place it e.g. in the parent directory of pd-mi-paradigm. So that you have the pd-mi-paradigm and pd-control-room paradigm in the same folder. Make sure to have all dependencies of the control room installed. Try pip install -r requirements.txt from within the pd-control-room folder.\nThen move into the dp-control-room directory and create a config at ./configs/mi_experiment.toml with the following content:\n[python]\nmodules_root = '../'\n\n# -------------------- used modules ---------------------------------------\n\n[python.modules.dp-mi-paradigm]\ntype = 'paradigm'\nport = 8081\nip = '127.0.0.1'\nloglevel = 10\nThen change the config which is loaded by the control room for convenience. So within ./control_room/main.py we place:\n\nsetup_cfg_path: Path = Path(\"./configs/mi_experiment.toml\").resolve()\nNow spawn up the control_room by calling python rcr.py or python -m control_room.main. You should now be able to see the control_room at 127.0.0.1:8050 within your browser. Make sure you see the mi_experiment section and a RUN button. If you click the button, you should see the paradigm being played.\n\n\nAs a final step, we add other modules and create a macro to control all with a single button push. So get the dp-mockup-streamer and the dp-lsl-recording module and place them in the same parent directory as the other modules.\n.\n├── dp-control-room\n├── dp-lsl-recording\n├── dp-mockup-streamer\n└── dp-mi-paradigm\nAlso install the requirements for the other two modules via pip install -r requirements.txt within each of the folders.\nThen add the following to the ./configs/mi_experiment.toml config:\n[python]\nmodules_root = '../'\n\n# -------------------- used modules ---------------------------------------\n\n[python.modules.dp-mi-paradigm]\ntype = 'paradigm'\nport = 8081\nip = '127.0.0.1'\nloglevel = 10\n\n[python.modules.dp-mockup-streamer]\ntype = 'source'\nport = 8082\nip = '127.0.0.1'\nloglevel = 10\n\n[python.modules.dp-lsl-recording]\ntype = 'paradigm'\nport = 8083\nip = '127.0.0.1'\nloglevel = 10\n\n\n[macros.start_test]\nname = 'START_TEST'\ndescription = 'start all modules for simulation'\ndelay_s = 1\n[macros.start_test.default_json]\nnrep = 6\n[macros.start_test.cmds]\n# variable names are arbitrary, the commands will be executes in the same order as they are read by tomllib\ncom1 = ['dp-mockup-streamer', 'START_RANDOM']\ncom2 = ['dp-lsl-recording', 'SELECT_ALL']\ncom4 = ['dp-lsl-recording', 'RECORD']\ncom5 = ['dp-mi-paradigm', 'RUN', 'nrepetitions=nrep']\n\n[macros.stop]\nname = 'STOP_TEST'\ndescription = 'Send a stop command to all involved modules'\n[macros.stop.cmds]\ncom1 = ['dp-lsl-recording', 'STOPRECORD']\nFor more details about how create a config for dp-control-room, please be referred to the README.\nBefore we restart the control room to check our new configuration including the macro, we need to start the LabRecorder. Otherwise the we will not be able to start the control room GUI. (Note - this is a temporary necessity. In later versions of the dp-lsl-recording module, this will be done automatically).\nNow restart the control room from within dp-control-room by using python rcr.py and you should see a Macro section on the GUI at 127.0.0.1:8050."
  },
  {
    "objectID": "examples/hello_world.html#get-the-dareplane-pyutils",
    "href": "examples/hello_world.html#get-the-dareplane-pyutils",
    "title": "Hello World for Dareplane with python modules",
    "section": "",
    "text": "Install the dareplane-utils to make use of the default TCP server. E.g. via pip install dareplane-utils."
  },
  {
    "objectID": "examples/hello_world.html#building-the-paradigm-module",
    "href": "examples/hello_world.html#building-the-paradigm-module",
    "title": "Hello World for Dareplane with python modules",
    "section": "",
    "text": "First, lets decide to call the module dp-mi-paradigm. The prefix of dp- for Dareplane is arbitrary and you can of course choose not to use it.\n\n\nTo start, get the dp-strawman-module and read the README.md therein carefully. After that you should know how to build upon the strawman. So lets rename the relevant folders. The content of our new module folder ./dp-mi-paradigm should then look like this:\n├── LICENSE\n├── README.md\n├── api\n│   └── server.py\n├── configs\n├── mi_paradigm\n│   ├── main.py\n│   └── utils\n│       └── logging.py\n└── tests\n\n\n\nFor our paradigm we decide to show simple instructions for motor imagination of left (L) and right ( R) hand movement by displaying letters ‘L’ and ‘R’ as well as a fixation cross ‘+’ using psychopy. In addition, we want to send markers to an LSL stream capturing when a direction is shown.\nSo our ./mi_paradigm/main.py could look like this.\n\nfrom fire import Fire\nimport time\nimport random\nimport pylsl\nfrom psychopy.visual import TextStim, Window\n\nfrom mi_paradigm.utils.logging import logger\n\nlogger.setLevel(10)\n\nBG_COLOR = (0, 0, 0)\nTEXT_COLOR = (1, 0, 0)\n\n# timing parameters\nt_pre = 1\nt_show = 1\nt_post = 1\n\n\n# LSL outlet - for convenience we also display to the logger\nclass Outlet:\n    def __init__(self):\n        self.logger = logger\n        info = pylsl.StreamInfo(name=\"markers\", channel_format=\"string\")\n        self.outlet = pylsl.StreamOutlet(info)\n\n    def push_sample(self, sample: str):\n        self.logger.debug(f\"Pushing sample {sample}\")\n        self.outlet.push_sample([sample])\n\n# Sometimes is is more convenient to have a paradigm instance which can be\n# kept alive globally. This especially holds if the server we will wrap around\n# this module will not call psychopy in a subprocess\n# --&gt; So for the example, add a class\nclass Paradigm:\n    def __init__(self):\n        self.open_window()\n\n    def open_window(self):\n        self.win = Window((800, 600), screen=1, color=BG_COLOR)\n        self.rstim = TextStim(win=self.win, text=\"R\", color=TEXT_COLOR)\n        self.lstim = TextStim(win=self.win, text=\"L\", color=TEXT_COLOR)\n        self.fix_cross = TextStim(win=self.win, text=\"+\", color=TEXT_COLOR)\n\n    def close_window(self):\n        self.win.close()\n\n\ndef run_mi_task(paradigm: Paradigm, nrepetitions: int = 4) -&gt; int:\n    outlet = Outlet()\n    win = paradigm.win\n    fix_cross = paradigm.fix_cross\n    rstim = paradigm.rstim\n    lstim = paradigm.lstim\n\n    fix_cross.draw()\n    win.flip()\n\n    # create a balanced set\n    directions = [\"R\"] * (nrepetitions // 2) + [\"L\"] * (nrepetitions // 2)\n    random.shuffle(directions)\n\n    for i, dir in enumerate(directions):\n        fix_cross.draw()\n        win.flip()\n        outlet.push_sample(\"new_trial\")\n\n        time.sleep(t_pre)\n\n        if dir == \"R\":\n            rstim.draw()\n        else:\n            lstim.draw()\n\n        win.flip()\n        outlet.push_sample(dir)\n\n        # clear screen and sleep for post\n        time.sleep(t_show)\n        win.flip()\n        outlet.push_sample(\"cleared\")\n\n        win.flip()\n        time.sleep(t_post)\n\n    return 0\n\n\nif __name__ == \"__main__\":\n\n    from functools import partial\n    pdm = Paradigm()\n    Fire(partial(run_mi_task, pdm))\nThis should be all we need for being able to test the paradigm via python -m mi_paradigm.main. Test it like this and make sure it works (especially installing requirements!).\n\n\n\nNext we need to add the server which will allow communication within a Dareplane setup. This requires just a few lines and since we started from the strawman, it actually just requires us to properly import the run_mi_task and Paradigm, intializing a Paradigm instance and adding it to the primary commands dictionary in ./api/server.py, partially defining the correct Paradigm instance.\nfrom fire import Fire\n\nfrom functools import partial\nfrom mi_paradigm.main import run_mi_task, Paradigm\nfrom mi_paradigm.utils.logging import logger\n\nfrom dareplane_utils.default_server.server import DefaultServer\n\n\ndef main(port: int = 8080, ip: str = \"127.0.0.1\", loglevel: int = 30):\n    pdm = Paradigm()\n\n    logger.setLevel(loglevel)\n    logger.debug(\"Paradigm created\")\n\n    # partial is used so taht the function call will use the pdm instance\n    pcommand_map = {\"RUN\": partial(run_mi_task, pdm)}\n\n   # ... rest is left unchanged\nNow you are ready for the next level of testing, which is to make sure, we can run the task via the server. Just spawn up the server with python -m api.server and connect via e.g. telnet 127.0.0.1 8080. Then send the RUN command in telnet and verify that the paradigm is played correctly.\nOnce this is successful, you have completed your first Dareplane module. Congratulations !"
  },
  {
    "objectID": "examples/hello_world.html#running-your-module-from-the-control-room",
    "href": "examples/hello_world.html#running-your-module-from-the-control-room",
    "title": "Hello World for Dareplane with python modules",
    "section": "",
    "text": "It is now time to integrate the dp-mi-paradigm with other modules. This is done using the dp-control-room. If you do not yet have it, clone it from git and place it e.g. in the parent directory of pd-mi-paradigm. So that you have the pd-mi-paradigm and pd-control-room paradigm in the same folder. Make sure to have all dependencies of the control room installed. Try pip install -r requirements.txt from within the pd-control-room folder.\nThen move into the dp-control-room directory and create a config at ./configs/mi_experiment.toml with the following content:\n[python]\nmodules_root = '../'\n\n# -------------------- used modules ---------------------------------------\n\n[python.modules.dp-mi-paradigm]\ntype = 'paradigm'\nport = 8081\nip = '127.0.0.1'\nloglevel = 10\nThen change the config which is loaded by the control room for convenience. So within ./control_room/main.py we place:\n\nsetup_cfg_path: Path = Path(\"./configs/mi_experiment.toml\").resolve()\nNow spawn up the control_room by calling python rcr.py or python -m control_room.main. You should now be able to see the control_room at 127.0.0.1:8050 within your browser. Make sure you see the mi_experiment section and a RUN button. If you click the button, you should see the paradigm being played.\n\n\nAs a final step, we add other modules and create a macro to control all with a single button push. So get the dp-mockup-streamer and the dp-lsl-recording module and place them in the same parent directory as the other modules.\n.\n├── dp-control-room\n├── dp-lsl-recording\n├── dp-mockup-streamer\n└── dp-mi-paradigm\nAlso install the requirements for the other two modules via pip install -r requirements.txt within each of the folders.\nThen add the following to the ./configs/mi_experiment.toml config:\n[python]\nmodules_root = '../'\n\n# -------------------- used modules ---------------------------------------\n\n[python.modules.dp-mi-paradigm]\ntype = 'paradigm'\nport = 8081\nip = '127.0.0.1'\nloglevel = 10\n\n[python.modules.dp-mockup-streamer]\ntype = 'source'\nport = 8082\nip = '127.0.0.1'\nloglevel = 10\n\n[python.modules.dp-lsl-recording]\ntype = 'paradigm'\nport = 8083\nip = '127.0.0.1'\nloglevel = 10\n\n\n[macros.start_test]\nname = 'START_TEST'\ndescription = 'start all modules for simulation'\ndelay_s = 1\n[macros.start_test.default_json]\nnrep = 6\n[macros.start_test.cmds]\n# variable names are arbitrary, the commands will be executes in the same order as they are read by tomllib\ncom1 = ['dp-mockup-streamer', 'START_RANDOM']\ncom2 = ['dp-lsl-recording', 'SELECT_ALL']\ncom4 = ['dp-lsl-recording', 'RECORD']\ncom5 = ['dp-mi-paradigm', 'RUN', 'nrepetitions=nrep']\n\n[macros.stop]\nname = 'STOP_TEST'\ndescription = 'Send a stop command to all involved modules'\n[macros.stop.cmds]\ncom1 = ['dp-lsl-recording', 'STOPRECORD']\nFor more details about how create a config for dp-control-room, please be referred to the README.\nBefore we restart the control room to check our new configuration including the macro, we need to start the LabRecorder. Otherwise the we will not be able to start the control room GUI. (Note - this is a temporary necessity. In later versions of the dp-lsl-recording module, this will be done automatically).\nNow restart the control room from within dp-control-room by using python rcr.py and you should see a Macro section on the GUI at 127.0.0.1:8050."
  },
  {
    "objectID": "examples/c-VEP_setup.html",
    "href": "examples/c-VEP_setup.html",
    "title": "c-VEP demo setup script",
    "section": "",
    "text": "c-VEP demo setup script\nIn this example, we walk over the details of the c-VEP demo setup script.\nSetup scripts for Dareplane provide an easy way to configure and share a full experimental setup. The idea is to download and configure all necessary components from scratch. Together with version control, this makes it easy to reproduce experiments and share them with others.\n\nPre requisists\n\nLSL Lab recorder is installed"
  },
  {
    "objectID": "modules/dp-control-room/reference/connection.html",
    "href": "modules/dp-control-room/reference/connection.html",
    "title": "connection",
    "section": "",
    "text": "connection\nconnection"
  },
  {
    "objectID": "modules/dp-control-room/reference/socket.html",
    "href": "modules/dp-control-room/reference/socket.html",
    "title": "socket",
    "section": "",
    "text": "socket\nsocket"
  },
  {
    "objectID": "modules/dp-control-room/reference/gui.callbacks.html",
    "href": "modules/dp-control-room/reference/gui.callbacks.html",
    "title": "gui.callbacks",
    "section": "",
    "text": "gui.callbacks\n\n\n\n\n\nName\nDescription\n\n\n\n\nadd_callbacks\nAdd callbacks to a given app\n\n\nadd_json_verification_cb\nCheck the json strings in each inbox\n\n\nevaluate_templates\nIf a dictionary contains $ templates in its values,\n\n\nmake_ao_payload_from_json\nTransform a json string to pipe separated list of values only\n\n\n\n\n\ngui.callbacks.add_callbacks(app, modules, macros=None)\nAdd callbacks to a given app\n\n\n\ngui.callbacks.add_json_verification_cb(app, modules, macros)\nCheck the json strings in each inbox\n\n\n\ngui.callbacks.evaluate_templates(d)\nIf a dictionary contains $ templates in its values, replace them with the variable\n\n\n\ngui.callbacks.make_ao_payload_from_json(json_payload)\nTransform a json string to pipe separated list of values only"
  },
  {
    "objectID": "modules/dp-control-room/reference/gui.callbacks.html#functions",
    "href": "modules/dp-control-room/reference/gui.callbacks.html#functions",
    "title": "gui.callbacks",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nadd_callbacks\nAdd callbacks to a given app\n\n\nadd_json_verification_cb\nCheck the json strings in each inbox\n\n\nevaluate_templates\nIf a dictionary contains $ templates in its values,\n\n\nmake_ao_payload_from_json\nTransform a json string to pipe separated list of values only\n\n\n\n\n\ngui.callbacks.add_callbacks(app, modules, macros=None)\nAdd callbacks to a given app\n\n\n\ngui.callbacks.add_json_verification_cb(app, modules, macros)\nCheck the json strings in each inbox\n\n\n\ngui.callbacks.evaluate_templates(d)\nIf a dictionary contains $ templates in its values, replace them with the variable\n\n\n\ngui.callbacks.make_ao_payload_from_json(json_payload)\nTransform a json string to pipe separated list of values only"
  },
  {
    "objectID": "modules/dp-control-room/reference/processes.html",
    "href": "modules/dp-control-room/reference/processes.html",
    "title": "processes",
    "section": "",
    "text": "processes\n\n\n\n\n\nName\nDescription\n\n\n\n\nclose_child_processes\nClose all child processes of a Popen instance\n\n\nstart_container\nGiven the configs for python, create subprocesses running the given modules\n\n\n\n\n\nprocesses.close_child_processes(process)\nClose all child processes of a Popen instance\n\n\n\nprocesses.start_container(\n    module_name,\n    ip,\n    port,\n    loglevel=10,\n    modules_root_path=Path('.'),\n    start_kwargs={},\n)\nGiven the configs for python, create subprocesses running the given modules\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nsubprocess.Popen"
  },
  {
    "objectID": "modules/dp-control-room/reference/processes.html#functions",
    "href": "modules/dp-control-room/reference/processes.html#functions",
    "title": "processes",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nclose_child_processes\nClose all child processes of a Popen instance\n\n\nstart_container\nGiven the configs for python, create subprocesses running the given modules\n\n\n\n\n\nprocesses.close_child_processes(process)\nClose all child processes of a Popen instance\n\n\n\nprocesses.start_container(\n    module_name,\n    ip,\n    port,\n    loglevel=10,\n    modules_root_path=Path('.'),\n    start_kwargs={},\n)\nGiven the configs for python, create subprocesses running the given modules\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nsubprocess.Popen"
  },
  {
    "objectID": "modules/dp-control-room/reference/utils.logserver.html",
    "href": "modules/dp-control-room/reference/utils.logserver.html",
    "title": "utils.logserver",
    "section": "",
    "text": "utils.logserver\nutils.logserver"
  },
  {
    "objectID": "modules/dp-stroop/reference/context.StroopContext.html",
    "href": "modules/dp-stroop/reference/context.StroopContext.html",
    "title": "context.StroopContext",
    "section": "",
    "text": "stroop_task.context.StroopContext(\n    self,\n    language,\n    word_color_dict=dict(),\n    msgs=dict(),\n    startblock_mrk=64,\n    endblock_mrk=64,\n    starttrial_mrk=2,\n    endtrial_mrk=4,\n    congruent_mrk=0,\n    incongruent_mrk=0,\n    lift_off_mrk=8,\n    reaction_mrk=16,\n    timeout_mrk=16,\n    stimulus_time_s=3.0,\n    pre_stimulus_time_s=1.0,\n    wait_time_min_s=1.0,\n    wait_time_max_s=2.0,\n    instruction_time_s=1000.0,\n    results_show_time_s=5.0,\n    arrow_down_press_to_continue_s=0.5,\n    classical_timeout_s=45,\n    focus='color',\n    reactions=list(),\n    block_stimuli=list(),\n    known_stimuli=dict(),\n    current_stimulus_idx=0,\n    current_stimuli=list(),\n    white_y_offset_px=100,\n    font_size=36,\n    instruction_font_size=16,\n    fullscreen=False,\n    screen_width=800,\n    screen_height=600,\n    tic=0,\n    tic_down=0,\n    marker_writer=get_marker_writer(),\n    has_window_attached=False,\n)\nA class to represent the context for the Stroop task.\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\nlanguage\nstr\nThe language setting for the Stroop task.\n\n\nword_color_dict\ndict\nA dictionary mapping words to their corresponding colors. See configs/.yaml.\n\n\nmsgs\ndict\nA dictionary containing messages for the Stroop task. See configs/.yaml.\n\n\nstartblock_mrk\nint\nMarker for the start of a block. See configs/task.yaml.\n\n\nendblock_mrk\nint\nMarker for the end of a block. See configs/task.yaml.\n\n\nstarttrial_mrk\nint\nMarker for the start of a trial. See configs/task.yaml.\n\n\nendtrial_mrk\nint\nMarker for the end of a trial. See configs/task.yaml.\n\n\ncongruent_mrk\nint\nMarker for congruent stimuli. See configs/task.yaml.\n\n\nincongruent_mrk\nint\nMarker for incongruent stimuli. See configs/task.yaml.\n\n\nlift_off_mrk\nint\nMarker for lift-off. See configs/task.yaml.\n\n\nreaction_mrk\nint\nMarker for reaction. See configs/task.yaml.\n\n\ntimeout_mrk\nint\nMarker for timeout. See configs/task.yaml.\n\n\nstimulus_time_s\nfloat\nDuration in seconds for stimulus presentation. See configs/task.yaml.\n\n\npre_stimulus_time_s\nfloat\nDuration in seconds for pre-stimulus interval. See configs/task.yaml.\n\n\nwait_time_min_s\nfloat\nMinimum wait time in seconds. See configs/task.yaml.\n\n\nwait_time_max_s\nfloat\nMaximum wait time in seconds. See configs/task.yaml.\n\n\ninstruction_time_s\nfloat\nDuration in seconds for instruction display. See configs/task.yaml.\n\n\nresults_show_time_s\nfloat\nDuration in seconds for results display. See configs/task.yaml.\n\n\narrow_down_press_to_continue_s\nfloat\nDuration in seconds for arrow down press to continue. See configs/task.yaml.\n\n\nclassical_timeout_s\nfloat\nTimeout duration in seconds for classical tasks. See configs/task.yaml.\n\n\nfocus\nLiteral['text', 'color']\nFocus of the Stroop task, either “text” or “color”.\n\n\nreactions\nlist\nList to track reactions.\n\n\nblock_stimuli\nlist\nList of stimuli for the current block.\n\n\nknown_stimuli\ndict\nDictionary of known stimuli.\n\n\ncurrent_stimulus_idx\nint\nIndex of the current stimulus.\n\n\ncurrent_stimuli\nlist\nList of current stimuli for drawing.\n\n\nwhite_y_offset_px\nint\nY-offset in pixels for white stimuli. See configs/gui.\n\n\nfont_size\nint\nFont size for stimuli. See configs/gui.\n\n\ninstruction_font_size\nint\nFont size for instructions. See configs/gui.\n\n\nfullscreen\nbool\nFlag for fullscreen mode. See configs/gui.\n\n\nscreen_width\nint\nWidth of the screen. See configs/gui.\n\n\nscreen_height\nint\nHeight of the screen. See configs/gui.\n\n\ntic\nfloat\nTime keeping variable.\n\n\ntic_down\nfloat\nTime keeping variable for countdown.\n\n\nmarker_writer\nMarkerWriter\nMarker writer for the Stroop task.\n\n\nhas_window_attached\nbool\nFlag indicating if a window is attached.\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nadd_instruction_screen_batch\nLoad all components and add them to an intro batch\n\n\nclose_context\nClose the context stopping all pyglet elements\n\n\ncreate_classical_examples_to_batch\nNot the full table just a few examples for the instruction screen\n\n\ncreate_classical_table_stimulus\nCreate a classical table stimulus for the Stroop task.\n\n\ncreate_stimuli\nCreate stimuli for the stroop task using WORD_COLOR_PAIRS from self.word_color_dict\n\n\ninit_block_stimuli\nInitialize a block of trials by modifying a context. The stimuli will\n\n\n\n\n\nstroop_task.context.StroopContext.add_instruction_screen_batch(\n    random_wait=False,\n)\nLoad all components and add them to an intro batch\n\n\n\nstroop_task.context.StroopContext.close_context()\nClose the context stopping all pyglet elements\n\n\n\nstroop_task.context.StroopContext.create_classical_examples_to_batch(batch)\nNot the full table just a few examples for the instruction screen\n\n\n\nstroop_task.context.StroopContext.create_classical_table_stimulus(\n    n_stimuli=60,\n    n_per_row=6,\n    perc_incongruent=0.33,\n)\nCreate a classical table stimulus for the Stroop task.\nThis method generates a table of stimuli for the Stroop task, where each stimulus is either congruent or incongruent based on the specified percentage. The stimuli are arranged in rows and columns, and the table is stored in the known_stimuli dictionary under the key “classical_batch”. The labels for each stimulus are also stored under the key “classical_labels”.\nThe generated table is saved as a CSV file in the stroop_task/assets directory to cache the layout. This will speed up the loading.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nn_stimuli\nint\nThe total number of stimuli to generate. Default is 60.\n60\n\n\nn_per_row\nint\nThe number of stimuli per row in the table. Default is 6.\n6\n\n\nperc_incongruent\nfloat\nThe percentage of incongruent stimuli in the table. Default is 0.33.\n0.33\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nNone\n\n\n\n\n\n\n\n\nstroop_task.context.StroopContext.create_stimuli(random_wait=False)\nCreate stimuli for the stroop task using WORD_COLOR_PAIRS from self.word_color_dict\n\n\n\nstroop_task.context.StroopContext.init_block_stimuli(n_trials)\nInitialize a block of trials by modifying a context. The stimuli will be accessible in ctx.block_stimuli as list of tuples (word, pyglet.text.Label, pyglet.shapes.Rectangle, pyglet.shapes.Rectangle, str) The shapes are the squares that will be shown left and right of the word, while the final string indicates the correct direction\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nn_trials\nint\nnumber of trials per block\nrequired"
  },
  {
    "objectID": "modules/dp-stroop/reference/context.StroopContext.html#attributes",
    "href": "modules/dp-stroop/reference/context.StroopContext.html#attributes",
    "title": "context.StroopContext",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\nlanguage\nstr\nThe language setting for the Stroop task.\n\n\nword_color_dict\ndict\nA dictionary mapping words to their corresponding colors. See configs/.yaml.\n\n\nmsgs\ndict\nA dictionary containing messages for the Stroop task. See configs/.yaml.\n\n\nstartblock_mrk\nint\nMarker for the start of a block. See configs/task.yaml.\n\n\nendblock_mrk\nint\nMarker for the end of a block. See configs/task.yaml.\n\n\nstarttrial_mrk\nint\nMarker for the start of a trial. See configs/task.yaml.\n\n\nendtrial_mrk\nint\nMarker for the end of a trial. See configs/task.yaml.\n\n\ncongruent_mrk\nint\nMarker for congruent stimuli. See configs/task.yaml.\n\n\nincongruent_mrk\nint\nMarker for incongruent stimuli. See configs/task.yaml.\n\n\nlift_off_mrk\nint\nMarker for lift-off. See configs/task.yaml.\n\n\nreaction_mrk\nint\nMarker for reaction. See configs/task.yaml.\n\n\ntimeout_mrk\nint\nMarker for timeout. See configs/task.yaml.\n\n\nstimulus_time_s\nfloat\nDuration in seconds for stimulus presentation. See configs/task.yaml.\n\n\npre_stimulus_time_s\nfloat\nDuration in seconds for pre-stimulus interval. See configs/task.yaml.\n\n\nwait_time_min_s\nfloat\nMinimum wait time in seconds. See configs/task.yaml.\n\n\nwait_time_max_s\nfloat\nMaximum wait time in seconds. See configs/task.yaml.\n\n\ninstruction_time_s\nfloat\nDuration in seconds for instruction display. See configs/task.yaml.\n\n\nresults_show_time_s\nfloat\nDuration in seconds for results display. See configs/task.yaml.\n\n\narrow_down_press_to_continue_s\nfloat\nDuration in seconds for arrow down press to continue. See configs/task.yaml.\n\n\nclassical_timeout_s\nfloat\nTimeout duration in seconds for classical tasks. See configs/task.yaml.\n\n\nfocus\nLiteral['text', 'color']\nFocus of the Stroop task, either “text” or “color”.\n\n\nreactions\nlist\nList to track reactions.\n\n\nblock_stimuli\nlist\nList of stimuli for the current block.\n\n\nknown_stimuli\ndict\nDictionary of known stimuli.\n\n\ncurrent_stimulus_idx\nint\nIndex of the current stimulus.\n\n\ncurrent_stimuli\nlist\nList of current stimuli for drawing.\n\n\nwhite_y_offset_px\nint\nY-offset in pixels for white stimuli. See configs/gui.\n\n\nfont_size\nint\nFont size for stimuli. See configs/gui.\n\n\ninstruction_font_size\nint\nFont size for instructions. See configs/gui.\n\n\nfullscreen\nbool\nFlag for fullscreen mode. See configs/gui.\n\n\nscreen_width\nint\nWidth of the screen. See configs/gui.\n\n\nscreen_height\nint\nHeight of the screen. See configs/gui.\n\n\ntic\nfloat\nTime keeping variable.\n\n\ntic_down\nfloat\nTime keeping variable for countdown.\n\n\nmarker_writer\nMarkerWriter\nMarker writer for the Stroop task.\n\n\nhas_window_attached\nbool\nFlag indicating if a window is attached."
  },
  {
    "objectID": "modules/dp-stroop/reference/context.StroopContext.html#methods",
    "href": "modules/dp-stroop/reference/context.StroopContext.html#methods",
    "title": "context.StroopContext",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nadd_instruction_screen_batch\nLoad all components and add them to an intro batch\n\n\nclose_context\nClose the context stopping all pyglet elements\n\n\ncreate_classical_examples_to_batch\nNot the full table just a few examples for the instruction screen\n\n\ncreate_classical_table_stimulus\nCreate a classical table stimulus for the Stroop task.\n\n\ncreate_stimuli\nCreate stimuli for the stroop task using WORD_COLOR_PAIRS from self.word_color_dict\n\n\ninit_block_stimuli\nInitialize a block of trials by modifying a context. The stimuli will\n\n\n\n\n\nstroop_task.context.StroopContext.add_instruction_screen_batch(\n    random_wait=False,\n)\nLoad all components and add them to an intro batch\n\n\n\nstroop_task.context.StroopContext.close_context()\nClose the context stopping all pyglet elements\n\n\n\nstroop_task.context.StroopContext.create_classical_examples_to_batch(batch)\nNot the full table just a few examples for the instruction screen\n\n\n\nstroop_task.context.StroopContext.create_classical_table_stimulus(\n    n_stimuli=60,\n    n_per_row=6,\n    perc_incongruent=0.33,\n)\nCreate a classical table stimulus for the Stroop task.\nThis method generates a table of stimuli for the Stroop task, where each stimulus is either congruent or incongruent based on the specified percentage. The stimuli are arranged in rows and columns, and the table is stored in the known_stimuli dictionary under the key “classical_batch”. The labels for each stimulus are also stored under the key “classical_labels”.\nThe generated table is saved as a CSV file in the stroop_task/assets directory to cache the layout. This will speed up the loading.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nn_stimuli\nint\nThe total number of stimuli to generate. Default is 60.\n60\n\n\nn_per_row\nint\nThe number of stimuli per row in the table. Default is 6.\n6\n\n\nperc_incongruent\nfloat\nThe percentage of incongruent stimuli in the table. Default is 0.33.\n0.33\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nNone\n\n\n\n\n\n\n\n\nstroop_task.context.StroopContext.create_stimuli(random_wait=False)\nCreate stimuli for the stroop task using WORD_COLOR_PAIRS from self.word_color_dict\n\n\n\nstroop_task.context.StroopContext.init_block_stimuli(n_trials)\nInitialize a block of trials by modifying a context. The stimuli will be accessible in ctx.block_stimuli as list of tuples (word, pyglet.text.Label, pyglet.shapes.Rectangle, pyglet.shapes.Rectangle, str) The shapes are the squares that will be shown left and right of the word, while the final string indicates the correct direction\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nn_trials\nint\nnumber of trials per block\nrequired"
  },
  {
    "objectID": "modules/dp-stroop/reference/task_manager.StroopTaskStateManager.html",
    "href": "modules/dp-stroop/reference/task_manager.StroopTaskStateManager.html",
    "title": "task_manager.StroopTaskStateManager",
    "section": "",
    "text": "stroop_task.task_manager.StroopTaskStateManager(self, ctx, random_wait=False)\nA state manager for the Stroop task providing callbacks for state transitions from: fixation -&gt; stimulus -&gt; random.wait -&gt; fixation …\nAdditionally, there is an instructions and end state.\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\nctx\nStroopContext\nThe context under which to operate.\n\n\ntransition_map\ndict\nA dictionary mapping state names to their corresponding callback methods.\n\n\nnext_state_transition\nNone\nPlaceholder for the next state transition.\n\n\nstates\nlist\nA list of states in the order they will appear.\n\n\ncurrent_state\nstr\nThe current state of the task.\n\n\ndown_pressed\nbool\nA flag indicating whether the down arrow key is pressed.\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nend_block\nEnd the block and log the results\n\n\nnext_state\nTransition to the next state. dt is only for compliance with pyglet\n\n\nrandom_wait\nUsing the clock scheduler as sub ms accuracy is not needed anyways\n\n\nshow_stimulus\nShow the next stimulus in the self.ctx.block_stimuli list\n\n\nstart_block\nStart a block of trials\n\n\n\n\n\nstroop_task.task_manager.StroopTaskStateManager.end_block()\nEnd the block and log the results\n\n\n\nstroop_task.task_manager.StroopTaskStateManager.next_state(dt=0.0)\nTransition to the next state. dt is only for compliance with pyglet callback signature\n\n\n\nstroop_task.task_manager.StroopTaskStateManager.random_wait()\nUsing the clock scheduler as sub ms accuracy is not needed anyways\n\n\n\nstroop_task.task_manager.StroopTaskStateManager.show_stimulus()\nShow the next stimulus in the self.ctx.block_stimuli list\n\n\n\nstroop_task.task_manager.StroopTaskStateManager.start_block()\nStart a block of trials"
  },
  {
    "objectID": "modules/dp-stroop/reference/task_manager.StroopTaskStateManager.html#attributes",
    "href": "modules/dp-stroop/reference/task_manager.StroopTaskStateManager.html#attributes",
    "title": "task_manager.StroopTaskStateManager",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\nctx\nStroopContext\nThe context under which to operate.\n\n\ntransition_map\ndict\nA dictionary mapping state names to their corresponding callback methods.\n\n\nnext_state_transition\nNone\nPlaceholder for the next state transition.\n\n\nstates\nlist\nA list of states in the order they will appear.\n\n\ncurrent_state\nstr\nThe current state of the task.\n\n\ndown_pressed\nbool\nA flag indicating whether the down arrow key is pressed."
  },
  {
    "objectID": "modules/dp-stroop/reference/task_manager.StroopTaskStateManager.html#methods",
    "href": "modules/dp-stroop/reference/task_manager.StroopTaskStateManager.html#methods",
    "title": "task_manager.StroopTaskStateManager",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nend_block\nEnd the block and log the results\n\n\nnext_state\nTransition to the next state. dt is only for compliance with pyglet\n\n\nrandom_wait\nUsing the clock scheduler as sub ms accuracy is not needed anyways\n\n\nshow_stimulus\nShow the next stimulus in the self.ctx.block_stimuli list\n\n\nstart_block\nStart a block of trials\n\n\n\n\n\nstroop_task.task_manager.StroopTaskStateManager.end_block()\nEnd the block and log the results\n\n\n\nstroop_task.task_manager.StroopTaskStateManager.next_state(dt=0.0)\nTransition to the next state. dt is only for compliance with pyglet callback signature\n\n\n\nstroop_task.task_manager.StroopTaskStateManager.random_wait()\nUsing the clock scheduler as sub ms accuracy is not needed anyways\n\n\n\nstroop_task.task_manager.StroopTaskStateManager.show_stimulus()\nShow the next stimulus in the self.ctx.block_stimuli list\n\n\n\nstroop_task.task_manager.StroopTaskStateManager.start_block()\nStart a block of trials"
  },
  {
    "objectID": "modules/dp-stroop/reference/utils.marker.utf8_write.html",
    "href": "modules/dp-stroop/reference/utils.marker.utf8_write.html",
    "title": "utils.marker.utf8_write",
    "section": "",
    "text": "stroop_task.utils.marker.utf8_write(port, data)\nConverts integer data into a UTF-8 byte string and writes it to the specified serial port.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nport\nserial.Serial\nThe serial port object to which the data will be written.\nrequired\n\n\ndata\nint\nThe integer data to be written to the serial port.\nrequired\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nint\nThe number of bytes written to the serial port."
  },
  {
    "objectID": "modules/dp-stroop/reference/utils.marker.utf8_write.html#parameters",
    "href": "modules/dp-stroop/reference/utils.marker.utf8_write.html#parameters",
    "title": "utils.marker.utf8_write",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nport\nserial.Serial\nThe serial port object to which the data will be written.\nrequired\n\n\ndata\nint\nThe integer data to be written to the serial port.\nrequired"
  },
  {
    "objectID": "modules/dp-stroop/reference/utils.marker.utf8_write.html#returns",
    "href": "modules/dp-stroop/reference/utils.marker.utf8_write.html#returns",
    "title": "utils.marker.utf8_write",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\n\nint\nThe number of bytes written to the serial port."
  },
  {
    "objectID": "modules/dp-stroop/reference/main.run_paradigm_classical.html",
    "href": "modules/dp-stroop/reference/main.run_paradigm_classical.html",
    "title": "main.run_paradigm_classical",
    "section": "",
    "text": "main.run_paradigm_classical\nstroop_task.main.run_paradigm_classical(\n    language='english',\n    logger_level=None,\n    focus='color',\n    write_to_serial=True,\n    random_wait=False,\n    classical_timeout_s=None,\n    show_fps=False,\n)\nThe arrangement and colors where drawn randomly once, but are then fixed"
  },
  {
    "objectID": "modules/dp-stroop/reference/main.run_paradigm_cli.html",
    "href": "modules/dp-stroop/reference/main.run_paradigm_cli.html",
    "title": "main.run_paradigm_cli",
    "section": "",
    "text": "stroop_task.main.run_paradigm_cli(\n    n_trials=60,\n    language='english',\n    logger_level=None,\n    focus='color',\n    write_to_serial=False,\n    random_wait=False,\n    classical=False,\n    classic_stroop_time_s=45,\n    show_fps=False,\n)\nStarting the Stroop paradigm standalone in a pyglet window\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nn_trials\nint (default: 60)\nNumber of trials to run in a block. Should be a multiple of 12 to ensure proper balancing\n60\n\n\nlanguage\nstr (default: \"english\")\nLanguage to use. Currently available: - “english” - “dutch” - “german”\n'english'\n\n\nlogger_level\nstr | None (default: None)\nConfiguration level for the logger. This will overwrite the value from configs/logging.yaml. Common python logging names are accepted: DEBUG, INFO, WARNING, ERROR\nNone\n\n\nfocus\nstr (default: \"color\")\nWhether the task was to focus on text or on color for the upper word. Just used in logging. Currently not implemented! -&gt; always focus on color\n'color'\n\n\nwrite_to_serial\nbool (default: False)\nIf True, the marker writer will also consider the configuration for the serial output. Not used if no serial marker hardware is connected.\nFalse\n\n\nrandom_wait\nbool (default: False)\nIf True, a random wait will be done between trials instead of waiting for the key down press. Timed as configured in configs/task.yaml.\nFalse\n\n\nclassical\nbool (default: False)\nIf True, the classical stroop paradigm will be run with displaying the color words on the screen as a table and the subject is asked to read as many as possible in a given time interval. Ask them to name the color of the font.\nFalse\n\n\nclassic_stroop_time_s\nfloat (default: 45)\nTime in seconds for the classical stroop task. Used if classical is True.\n45\n\n\nshow_fps\nbool\nIf True, the FPS will be shown on the screen.\nFalse"
  },
  {
    "objectID": "modules/dp-stroop/reference/main.run_paradigm_cli.html#parameters",
    "href": "modules/dp-stroop/reference/main.run_paradigm_cli.html#parameters",
    "title": "main.run_paradigm_cli",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nn_trials\nint (default: 60)\nNumber of trials to run in a block. Should be a multiple of 12 to ensure proper balancing\n60\n\n\nlanguage\nstr (default: \"english\")\nLanguage to use. Currently available: - “english” - “dutch” - “german”\n'english'\n\n\nlogger_level\nstr | None (default: None)\nConfiguration level for the logger. This will overwrite the value from configs/logging.yaml. Common python logging names are accepted: DEBUG, INFO, WARNING, ERROR\nNone\n\n\nfocus\nstr (default: \"color\")\nWhether the task was to focus on text or on color for the upper word. Just used in logging. Currently not implemented! -&gt; always focus on color\n'color'\n\n\nwrite_to_serial\nbool (default: False)\nIf True, the marker writer will also consider the configuration for the serial output. Not used if no serial marker hardware is connected.\nFalse\n\n\nrandom_wait\nbool (default: False)\nIf True, a random wait will be done between trials instead of waiting for the key down press. Timed as configured in configs/task.yaml.\nFalse\n\n\nclassical\nbool (default: False)\nIf True, the classical stroop paradigm will be run with displaying the color words on the screen as a table and the subject is asked to read as many as possible in a given time interval. Ask them to name the color of the font.\nFalse\n\n\nclassic_stroop_time_s\nfloat (default: 45)\nTime in seconds for the classical stroop task. Used if classical is True.\n45\n\n\nshow_fps\nbool\nIf True, the FPS will be shown on the screen.\nFalse"
  },
  {
    "objectID": "modules/dp-ao-communication/AUTHORS.html",
    "href": "modules/dp-ao-communication/AUTHORS.html",
    "title": "Contributors to dp-ao-communication",
    "section": "",
    "text": "Aron Distelzweig\n\nImplementation\n\nMatthias Dold\n\nDesign\nReworking build chain to make from cmake\nFull refactoring for C++23 and meson.build"
  },
  {
    "objectID": "modules/dp-ao-communication/AUTHORS.html#contributor-sorted-alphabetically",
    "href": "modules/dp-ao-communication/AUTHORS.html#contributor-sorted-alphabetically",
    "title": "Contributors to dp-ao-communication",
    "section": "",
    "text": "Aron Distelzweig\n\nImplementation\n\nMatthias Dold\n\nDesign\nReworking build chain to make from cmake\nFull refactoring for C++23 and meson.build"
  },
  {
    "objectID": "libraries/dareplane_utils/server.LogRecordStreamHandler.html",
    "href": "libraries/dareplane_utils/server.LogRecordStreamHandler.html",
    "title": "server.LogRecordStreamHandler",
    "section": "",
    "text": "dareplane_utils.logging.server.LogRecordStreamHandler()\nHandler for a streaming logging request.\nThis basically logs the record using whatever logging policy is configured locally.\n\n\n\n\n\nName\nDescription\n\n\n\n\nhandle\nHandle multiple requests - each expected to be a 4-byte length,\n\n\n\n\n\ndareplane_utils.logging.server.LogRecordStreamHandler.handle()\nHandle multiple requests - each expected to be a 4-byte length, followed by the LogRecord in pickle format. Logs the record according to whatever policy is configured locally.",
    "crumbs": [
      "Logging",
      "server.LogRecordStreamHandler"
    ]
  },
  {
    "objectID": "libraries/dareplane_utils/server.LogRecordStreamHandler.html#methods",
    "href": "libraries/dareplane_utils/server.LogRecordStreamHandler.html#methods",
    "title": "server.LogRecordStreamHandler",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nhandle\nHandle multiple requests - each expected to be a 4-byte length,\n\n\n\n\n\ndareplane_utils.logging.server.LogRecordStreamHandler.handle()\nHandle multiple requests - each expected to be a 4-byte length, followed by the LogRecord in pickle format. Logs the record according to whatever policy is configured locally.",
    "crumbs": [
      "Logging",
      "server.LogRecordStreamHandler"
    ]
  },
  {
    "objectID": "libraries/dareplane_utils/pylsl_xmlelement_to_dict.html",
    "href": "libraries/dareplane_utils/pylsl_xmlelement_to_dict.html",
    "title": "pylsl_xmlelement_to_dict",
    "section": "",
    "text": "pylsl_xmlelement_to_dict\ndareplane_utils.stream_watcher.lsl_stream_watcher.pylsl_xmlelement_to_dict(inf)\nThe pylsl XMLElement is hard to investigate -&gt; cast to a dict for simplicity",
    "crumbs": [
      "Streaming data",
      "pylsl_xmlelement_to_dict"
    ]
  },
  {
    "objectID": "libraries/dareplane_utils/get_streams_names.html",
    "href": "libraries/dareplane_utils/get_streams_names.html",
    "title": "get_streams_names",
    "section": "",
    "text": "dareplane_utils.stream_watcher.lsl_stream_watcher.get_streams_names()\nGet a list of all available lsl stream names.\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\nstreams\nlist[str]\nnames of all available LSL streams",
    "crumbs": [
      "Streaming data",
      "get_streams_names"
    ]
  },
  {
    "objectID": "libraries/dareplane_utils/get_streams_names.html#returns",
    "href": "libraries/dareplane_utils/get_streams_names.html#returns",
    "title": "get_streams_names",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\nstreams\nlist[str]\nnames of all available LSL streams",
    "crumbs": [
      "Streaming data",
      "get_streams_names"
    ]
  },
  {
    "objectID": "libraries/dareplane_utils/server.LogRecordSocketReceiver.html",
    "href": "libraries/dareplane_utils/server.LogRecordSocketReceiver.html",
    "title": "server.LogRecordSocketReceiver",
    "section": "",
    "text": "server.LogRecordSocketReceiver\ndareplane_utils.logging.server.LogRecordSocketReceiver(\n    self,\n    host='localhost',\n    port=logging.handlers.DEFAULT_TCP_LOGGING_PORT,\n    handler=LogRecordStreamHandler,\n    logfile=Path('default_socket.log'),\n)\nSimple TCP socket-based logging receiver suitable for testing.",
    "crumbs": [
      "Logging",
      "server.LogRecordSocketReceiver"
    ]
  },
  {
    "objectID": "libraries/dareplane_utils/DefaultServer.html",
    "href": "libraries/dareplane_utils/DefaultServer.html",
    "title": "DefaultServer",
    "section": "",
    "text": "dareplane_utils.default_server.server.DefaultServer(\n    self,\n    port=8080,\n    ip='0.0.0.0',\n    nlisten=10,\n    name='default_server',\n    thread_stopper=stop_thread,\n    proc_stopper=stop_process,\n    msg_interpreter=interpret_msg,\n    pcommand_map=dict(),\n    current_conn=None,\n    server_socket=None,\n    threads=dict(),\n    processes=dict(),\n    is_listening=False,\n    logger=get_logger(__name__),\n)\nThe default server which is being used and modified by pther dareplane projects\n\n\n\n\n\nName\nDescription\n\n\n\n\ndefault_msg_interpretation\nThis contains the default interpretation\n\n\nhandle_msg\ninterpret the message\n\n\nmsg_interpretation\nInterpret the message and perform book keeping if necessary\n\n\nshutdown\nShutdown the server and close all connections\n\n\n\n\n\ndareplane_utils.default_server.server.DefaultServer.default_msg_interpretation(\n    msg,\n)\nThis contains the default interpretation\n\n\n\ndareplane_utils.default_server.server.DefaultServer.handle_msg(msg)\ninterpret the message\n\n\n\ndareplane_utils.default_server.server.DefaultServer.msg_interpretation(msg)\nInterpret the message and perform book keeping if necessary\n\n\n\ndareplane_utils.default_server.server.DefaultServer.shutdown()\nShutdown the server and close all connections",
    "crumbs": [
      "Server",
      "DefaultServer"
    ]
  },
  {
    "objectID": "libraries/dareplane_utils/DefaultServer.html#methods",
    "href": "libraries/dareplane_utils/DefaultServer.html#methods",
    "title": "DefaultServer",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ndefault_msg_interpretation\nThis contains the default interpretation\n\n\nhandle_msg\ninterpret the message\n\n\nmsg_interpretation\nInterpret the message and perform book keeping if necessary\n\n\nshutdown\nShutdown the server and close all connections\n\n\n\n\n\ndareplane_utils.default_server.server.DefaultServer.default_msg_interpretation(\n    msg,\n)\nThis contains the default interpretation\n\n\n\ndareplane_utils.default_server.server.DefaultServer.handle_msg(msg)\ninterpret the message\n\n\n\ndareplane_utils.default_server.server.DefaultServer.msg_interpretation(msg)\nInterpret the message and perform book keeping if necessary\n\n\n\ndareplane_utils.default_server.server.DefaultServer.shutdown()\nShutdown the server and close all connections",
    "crumbs": [
      "Server",
      "DefaultServer"
    ]
  },
  {
    "objectID": "libraries/dareplane_utils/index.html",
    "href": "libraries/dareplane_utils/index.html",
    "title": "Documentation for dareplane_utils",
    "section": "",
    "text": "The server components can be used from dareplane_utils.default_server.server\n\n\n\nDefaultServer\nThe default server which is being used and modified by pther dareplane\n\n\n\n\n\n\nLogging components which add a TCP handler to a logger derived from Python’s standard logging.Logger. This allows to the dp-control-room to create a single consolidated log-file.\n\n\n\nlogger.get_logger\nGet a configured logger.\n\n\nserver.LogRecordStreamHandler\nHandler for a streaming logging request.\n\n\nserver.LogRecordSocketReceiver\nSimple TCP socket-based logging receiver suitable for testing.\n\n\nserver.modify_root_logger\n\n\n\n\n\n\n\nDareplane relies mostly on the lab streaming layer (LSL) for streaming data. A central element of the dareplane-utils is the StreamWatcher which is a ring buffer to read from streams. Currently we only have a StreamWatcher for LSL implemented, using pylsl and inlets defined therein.\n\n\n\nStreamWatcher\n\n\n\nget_streams_names\nGet a list of all available lsl stream names.\n\n\npylsl_xmlelement_to_dict\nThe pylsl XMLElement is hard to investigate -&gt; cast to a dict for\n\n\nget_channel_names\n\n\n\n\n\n\n\nGeneral utility functions and classes\n\n\n\nringbuffer.RingBuffer\n\n\n\ntime.sleep_s\nSleep for a specified duration with partial sleep optimization.\n\n\ntime.partial_sleep\nSleep for 90% of s or up to 30ms to the end, whatever is longer\n\n\ntime.full_speed\n\n\n\nevent_loop.EventLoop",
    "crumbs": [
      "Home",
      "Documentation",
      "dareplane-utils"
    ]
  },
  {
    "objectID": "libraries/dareplane_utils/index.html#server",
    "href": "libraries/dareplane_utils/index.html#server",
    "title": "Documentation for dareplane_utils",
    "section": "",
    "text": "The server components can be used from dareplane_utils.default_server.server\n\n\n\nDefaultServer\nThe default server which is being used and modified by pther dareplane",
    "crumbs": [
      "Home",
      "Documentation",
      "dareplane-utils"
    ]
  },
  {
    "objectID": "libraries/dareplane_utils/index.html#logging",
    "href": "libraries/dareplane_utils/index.html#logging",
    "title": "Documentation for dareplane_utils",
    "section": "",
    "text": "Logging components which add a TCP handler to a logger derived from Python’s standard logging.Logger. This allows to the dp-control-room to create a single consolidated log-file.\n\n\n\nlogger.get_logger\nGet a configured logger.\n\n\nserver.LogRecordStreamHandler\nHandler for a streaming logging request.\n\n\nserver.LogRecordSocketReceiver\nSimple TCP socket-based logging receiver suitable for testing.\n\n\nserver.modify_root_logger",
    "crumbs": [
      "Home",
      "Documentation",
      "dareplane-utils"
    ]
  },
  {
    "objectID": "libraries/dareplane_utils/index.html#streaming-data",
    "href": "libraries/dareplane_utils/index.html#streaming-data",
    "title": "Documentation for dareplane_utils",
    "section": "",
    "text": "Dareplane relies mostly on the lab streaming layer (LSL) for streaming data. A central element of the dareplane-utils is the StreamWatcher which is a ring buffer to read from streams. Currently we only have a StreamWatcher for LSL implemented, using pylsl and inlets defined therein.\n\n\n\nStreamWatcher\n\n\n\nget_streams_names\nGet a list of all available lsl stream names.\n\n\npylsl_xmlelement_to_dict\nThe pylsl XMLElement is hard to investigate -&gt; cast to a dict for\n\n\nget_channel_names",
    "crumbs": [
      "Home",
      "Documentation",
      "dareplane-utils"
    ]
  },
  {
    "objectID": "libraries/dareplane_utils/index.html#general",
    "href": "libraries/dareplane_utils/index.html#general",
    "title": "Documentation for dareplane_utils",
    "section": "",
    "text": "General utility functions and classes\n\n\n\nringbuffer.RingBuffer\n\n\n\ntime.sleep_s\nSleep for a specified duration with partial sleep optimization.\n\n\ntime.partial_sleep\nSleep for 90% of s or up to 30ms to the end, whatever is longer\n\n\ntime.full_speed\n\n\n\nevent_loop.EventLoop",
    "crumbs": [
      "Home",
      "Documentation",
      "dareplane-utils"
    ]
  },
  {
    "objectID": "libraries/dareplane_utils/StreamWatcher.html",
    "href": "libraries/dareplane_utils/StreamWatcher.html",
    "title": "StreamWatcher",
    "section": "",
    "text": "dareplane_utils.stream_watcher.lsl_stream_watcher.StreamWatcher(\n    self,\n    name='',\n    buffer_size_s=2,\n    logger=logger,\n)\n\n\n\n\n\nName\nDescription\n\n\n\n\nconnect_to_stream\nEither use the self.name or a provided identifier dict to hook up\n\n\ndisconnect\nDestroying the inlet will disconnect -&gt; see pylsl.pylsl.py\n\n\nupdate_numeric\nLook for new data and update the buffer\n\n\n\n\n\ndareplane_utils.stream_watcher.lsl_stream_watcher.StreamWatcher.connect_to_stream(\n    identifier=None,\n)\nEither use the self.name or a provided identifier dict to hook up with an LSL stream, they should coincide\n\n\n\ndareplane_utils.stream_watcher.lsl_stream_watcher.StreamWatcher.disconnect()\nDestroying the inlet will disconnect -&gt; see pylsl.pylsl.py\n\n\n\ndareplane_utils.stream_watcher.lsl_stream_watcher.StreamWatcher.update_numeric()\nLook for new data and update the buffer",
    "crumbs": [
      "Streaming data",
      "StreamWatcher"
    ]
  },
  {
    "objectID": "libraries/dareplane_utils/StreamWatcher.html#methods",
    "href": "libraries/dareplane_utils/StreamWatcher.html#methods",
    "title": "StreamWatcher",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nconnect_to_stream\nEither use the self.name or a provided identifier dict to hook up\n\n\ndisconnect\nDestroying the inlet will disconnect -&gt; see pylsl.pylsl.py\n\n\nupdate_numeric\nLook for new data and update the buffer\n\n\n\n\n\ndareplane_utils.stream_watcher.lsl_stream_watcher.StreamWatcher.connect_to_stream(\n    identifier=None,\n)\nEither use the self.name or a provided identifier dict to hook up with an LSL stream, they should coincide\n\n\n\ndareplane_utils.stream_watcher.lsl_stream_watcher.StreamWatcher.disconnect()\nDestroying the inlet will disconnect -&gt; see pylsl.pylsl.py\n\n\n\ndareplane_utils.stream_watcher.lsl_stream_watcher.StreamWatcher.update_numeric()\nLook for new data and update the buffer",
    "crumbs": [
      "Streaming data",
      "StreamWatcher"
    ]
  },
  {
    "objectID": "libraries/dareplane_utils/ringbuffer.RingBuffer.html",
    "href": "libraries/dareplane_utils/ringbuffer.RingBuffer.html",
    "title": "ringbuffer.RingBuffer",
    "section": "",
    "text": "dareplane_utils.general.ringbuffer.RingBuffer(self, shape, dtype=np.float32)\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\nbuffer\nnp.ndarray\nthe data buffer\n\n\nbuffer_t\nnp.ndarray\nthe time buffer\n\n\nlast_t\nfloat\nlatest time stamp\n\n\ncurr_i\nint\nindex of the latest data point int the buffer\n\n\nlogger\nlogging.Logger\nthe logger used for warnings and debug messages\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nshape\ntuple[int, int, …]\nshape of the buffer needs to be at least 2D (n_samples, n_features), arbitrary further dimensions can be added\nrequired\n\n\ndtype\ntype\na numpy data type for the buffer\nnp.float32\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nadd_continuous_buffer\nSlice samples should not be necessary &gt;&gt;&gt; as we add continuously\n\n\nget_insert_slices\nGet slices mapping data from the samples to the buffer\n\n\n\n\n\ndareplane_utils.general.ringbuffer.RingBuffer.add_continuous_buffer(\n    slice_buffer,\n    samples,\n    times,\n)\nSlice samples should not be necessary &gt;&gt;&gt; as we add continuously + slice selection from lists is slow\n\n\n\ndareplane_utils.general.ringbuffer.RingBuffer.get_insert_slices(len_samples)\nGet slices mapping data from the samples to the buffer\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nlen_samples\nint\nnumber of samples to add\nrequired\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\ntuple[list[slice], list[slice], int]",
    "crumbs": [
      "General",
      "ringbuffer.RingBuffer"
    ]
  },
  {
    "objectID": "libraries/dareplane_utils/ringbuffer.RingBuffer.html#attributes",
    "href": "libraries/dareplane_utils/ringbuffer.RingBuffer.html#attributes",
    "title": "ringbuffer.RingBuffer",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\nbuffer\nnp.ndarray\nthe data buffer\n\n\nbuffer_t\nnp.ndarray\nthe time buffer\n\n\nlast_t\nfloat\nlatest time stamp\n\n\ncurr_i\nint\nindex of the latest data point int the buffer\n\n\nlogger\nlogging.Logger\nthe logger used for warnings and debug messages",
    "crumbs": [
      "General",
      "ringbuffer.RingBuffer"
    ]
  },
  {
    "objectID": "libraries/dareplane_utils/ringbuffer.RingBuffer.html#parameters",
    "href": "libraries/dareplane_utils/ringbuffer.RingBuffer.html#parameters",
    "title": "ringbuffer.RingBuffer",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nshape\ntuple[int, int, …]\nshape of the buffer needs to be at least 2D (n_samples, n_features), arbitrary further dimensions can be added\nrequired\n\n\ndtype\ntype\na numpy data type for the buffer\nnp.float32",
    "crumbs": [
      "General",
      "ringbuffer.RingBuffer"
    ]
  },
  {
    "objectID": "libraries/dareplane_utils/ringbuffer.RingBuffer.html#methods",
    "href": "libraries/dareplane_utils/ringbuffer.RingBuffer.html#methods",
    "title": "ringbuffer.RingBuffer",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nadd_continuous_buffer\nSlice samples should not be necessary &gt;&gt;&gt; as we add continuously\n\n\nget_insert_slices\nGet slices mapping data from the samples to the buffer\n\n\n\n\n\ndareplane_utils.general.ringbuffer.RingBuffer.add_continuous_buffer(\n    slice_buffer,\n    samples,\n    times,\n)\nSlice samples should not be necessary &gt;&gt;&gt; as we add continuously + slice selection from lists is slow\n\n\n\ndareplane_utils.general.ringbuffer.RingBuffer.get_insert_slices(len_samples)\nGet slices mapping data from the samples to the buffer\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nlen_samples\nint\nnumber of samples to add\nrequired\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\ntuple[list[slice], list[slice], int]",
    "crumbs": [
      "General",
      "ringbuffer.RingBuffer"
    ]
  }
]